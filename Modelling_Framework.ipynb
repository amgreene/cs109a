{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "import datetime\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.cross_validation import KFold as kfold\n",
    "from sklearn.decomposition import TruncatedSVD as tSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import LogisticRegression as Log_Reg\n",
    "from sklearn.linear_model import LogisticRegressionCV as Log_Reg_CV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from scipy.io import mmread\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') \n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_expected_profit(profit_data_test, test_y_hat):\n",
    "    interest_revenue = model_loan_term * profit_data_test.installment[test_y_hat == True].sum()\n",
    "    recoveries = recoveries_avg * (test_y_hat == False).sum()\n",
    "    principal_losses = profit_data_test.loan_amount[test_y_hat == False].sum()\n",
    "    profit_mm = round(interest_revenue + recoveries - principal_losses) / float(10 ** 6)\n",
    "    return profit_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ROC_plot(model, X, Y, model_name):\n",
    "    # Plot the ROC curve for the given model\n",
    "    roc_data = []\n",
    "    # Note that the values actually start in the upper right and move to the lower left as p increases\n",
    "    # so we need to initialize these at (1, 1) not at (0, 0) for the numeric intergation\n",
    "    prev_false_positive = 1\n",
    "    prev_true_positive = 1\n",
    "    auc = 0  # rough integral\n",
    "    predicted_prob = model.predict_proba(X)[:,1]\n",
    "\n",
    "    # Draw ROC curve and use numeric integration to compute AUC\n",
    "    for p in np.arange(0, 1, 0.01):\n",
    "        yhat = predicted_prob >= p\n",
    "        false_positive_rate = ((yhat == 1) & (Y == 0)).sum() * 1.0 / ((Y == 0).sum())\n",
    "        true_positive_rate = ((yhat == 1) & (Y == 1)).sum() * 1.0 / ((Y == 1).sum())\n",
    "        roc_data.append((false_positive_rate, true_positive_rate))\n",
    "        # mark the key thresholds that we might use\n",
    "        if p in (0.5, 0.6, 0.85):\n",
    "            plt.scatter(false_positive_rate, true_positive_rate)  \n",
    "        # Use midpoint rectangle method to approximate AUC\n",
    "        auc += (true_positive_rate + prev_true_positive) / 2.0 * (prev_false_positive - false_positive_rate)\n",
    "        prev_false_positive = false_positive_rate\n",
    "        prev_true_positive = true_positive_rate\n",
    "\n",
    "    # Close off the curve by ending at (0, 0) regardless of what the last point was\n",
    "    roc_data.append((0, 0))\n",
    "    # Use midpoint rectangle method to approximate AUC\n",
    "    auc += (0 + prev_true_positive) / 2.0 * (prev_false_positive - 0)\n",
    "\n",
    "    plt.plot([roc[0] for roc in roc_data],\n",
    "             [roc[1] for roc in roc_data],\n",
    "            )\n",
    "    plt.xlim(-.01, 1.0)\n",
    "    plt.ylim(0, 1.01)\n",
    "    plt.title(\"ROC Curve for \" + model_name)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.gca().text(0.99, 0.1, \"AUC = %.3f\" % (auc,),\n",
    "                   ha = 'right', va = 'bottom'\n",
    "    )\n",
    "    plt.savefig('docs/images/roc_' + model_name.replace('/', '_') + '.png',\n",
    "                bbox_inches='tight'\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_terms(x, poly_degree):\n",
    "    # compute cross terms -- but not two one-hots against each other, because memory\n",
    "    x_out = x[x.columns]\n",
    "    for degree in range(2, poly_degree+1):\n",
    "        for col in x.columns:\n",
    "            if '__' in col:\n",
    "                continue\n",
    "            x_out[col + '^' + str(degree)] = x[col] ** degree\n",
    "    for c1, c2 in combinations(x.columns, 2):\n",
    "        if '__' in c1 and '__' in c2:\n",
    "            continue\n",
    "        x_out[c1 + ' x ' + c2] = x[c1] * x[c2]\n",
    "    return x_out\n",
    "\n",
    "def cross_term_names(x, poly_degree):\n",
    "    # compute cross terms -- but not two one-hots against each other, because memory\n",
    "    x_out = list(x.columns)\n",
    "    for degree in range(2, poly_degree+1):\n",
    "        for col in x.columns:\n",
    "            if '__' in col:\n",
    "                continue\n",
    "            x_out += [col + '^' + str(degree)]\n",
    "    for c1, c2 in combinations(x.columns, 2):\n",
    "        if '__' in c1 and '__' in c2:\n",
    "            continue\n",
    "        x_out += [c1 + ' x ' + c2]\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_expanded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2efe246392f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mpoly_degree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          \u001b[0mprob_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                          \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_expanded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                          \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test_expanded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                          \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_expanded' is not defined"
     ]
    }
   ],
   "source": [
    "def eval_model_all_years(model_factory, \n",
    "                         columns = None, \n",
    "                         poly_degree = None, \n",
    "                         prob_threshold = 0.5, \n",
    "                         x = x_expanded, \n",
    "                         x_test = x_test_expanded, \n",
    "                         y = y, \n",
    "                         y_test = y_test,\n",
    "                         years = years, \n",
    "                         years_test = years_test, \n",
    "                         profit_data_test = profit_data_test,\n",
    "                         model_name = None):\n",
    "    k = 5\n",
    "    np.random.seed(1729)\n",
    "    \n",
    "    if columns is None:\n",
    "        x_local = x\n",
    "        x_local_test = x_test\n",
    "    else:\n",
    "        # expand column names for factors\n",
    "        columns = [c for c in x.columns\n",
    "                   if (c in columns\n",
    "                       or c.split('__')[0] in columns)]\n",
    "        x_local = x[columns]\n",
    "        x_local_test = x_test[columns]\n",
    "        \n",
    "    if poly_degree is not None:\n",
    "        x_local = cross_terms(x_local, poly_degree)\n",
    "        x_local_test = cross_terms(x_local_test, poly_degree)\n",
    "        \n",
    "    indexes = range(len(years))\n",
    "    np.random.shuffle(indexes)\n",
    "\n",
    "    cm_accum = np.zeros((2, 2))\n",
    "    f1_accum = 0\n",
    "    score = 0\n",
    "    precision = 0\n",
    "\n",
    "    # k-fold cross-validation\n",
    "    for i in range(k):\n",
    "        train_indexes = list(indexes[0:len(indexes)*i/k]) + list(indexes[len(indexes)*(i+1)/k:])\n",
    "        test_indexes = indexes[len(indexes)*i/k:len(indexes)*(i+1)/k]\n",
    "\n",
    "        model = model_factory().fit(x_local.iloc[train_indexes,:], y.iloc[train_indexes])\n",
    "        y_hat = model.predict(x_local)\n",
    "        score += model.score(x_local.iloc[test_indexes], y.iloc[test_indexes]) / k\n",
    "        y_hat_weighted = (model.predict_proba(x_local)[:,0] > prob_threshold)[test_indexes]\n",
    "        precision += (y.iloc[test_indexes][y_hat_weighted]).mean() / k\n",
    "        cm_accum += confusion_matrix(y.iloc[test_indexes], y_hat[test_indexes])\n",
    "        f1_accum += f1_score(y.iloc[test_indexes], y_hat[test_indexes], pos_label = 1) / k\n",
    "\n",
    "        if model_name is None:\n",
    "            model_name = type(model).__name__\n",
    "\n",
    "    # but also test against the x_test\n",
    "    model = model_factory().fit(x_local, y)\n",
    "    test_y_hat = (model.predict_proba(x_local_test)[:,0] > prob_threshold)\n",
    "    test_score = model.score(x_local_test, y_test)\n",
    "    test_precision = y_test[test_y_hat].mean()\n",
    "    test_f1 = f1_score(y_test, test_y_hat, pos_label = 1)\n",
    "\n",
    "    # expected profit\n",
    "    profit_mm = calc_expected_profit(profit_data_test, test_y_hat)\n",
    "\n",
    "    area_under_curve = ROC_plot(model, x_local_test, y_test, model_name)\n",
    "\n",
    "    print \"all   score: %.3f  baseline: %.3f   prec: %.3f   f1: %.3f  | test score %.3f  prec %.3f f1 %.3f  GP %dMM\" % (\n",
    "        score, y.mean(), precision, f1_accum, test_score, test_precision, test_f1, profit_mm)\n",
    "\n",
    "    model_performance[model_name] = {\n",
    "        'score': score,\n",
    "        'baseline' : y.mean(),\n",
    "        'prec' : precision,\n",
    "        'f1': f1_accum,\n",
    "        'test_score': test_score,\n",
    "        'test_prec': test_precision,\n",
    "        'test_f1': test_f1,\n",
    "        'test_profit': profit_mm,\n",
    "        'auc': area_under_curve,\n",
    "    }\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_model_by_year(model_factory, \n",
    "                       columns = None, \n",
    "                       prob_threshold = 0.5,\n",
    "                       x = x_expanded, \n",
    "                       x_test = x_test_expanded, \n",
    "                       y = y, \n",
    "                       y_test = y_test,\n",
    "                       years = years, \n",
    "                       years_test = years_test,\n",
    "                       profit_data_test = profit_data_test,\n",
    "                       model_name = None):\n",
    "\n",
    "    # Start with an overview\n",
    "    all_years_model = eval_model_all_years(\n",
    "                         model_factory, columns, None, prob_threshold, \n",
    "                         x, x_test, y, y_test, years, years_test,\n",
    "                         profit_data_test, \n",
    "                         model_name = model_name)\n",
    "    k = 5\n",
    "    np.random.seed(1729)\n",
    "    \n",
    "    if columns is None:\n",
    "        x_local = x\n",
    "        x_local_test = x_test\n",
    "    else:\n",
    "        x_local = x[columns]\n",
    "        x_local_test = x_test[columns]\n",
    "        \n",
    "    for yr in [2011, 2012, 2013]: # set(years.values):\n",
    "        indexes = np.where(years == yr)[0]\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "        cm_accum = np.zeros((2, 2))\n",
    "        f1_accum = 0\n",
    "        score = 0\n",
    "        precision = 0\n",
    "\n",
    "        # k-fold cross-validation\n",
    "        for i in range(k):\n",
    "            train_indexes = list(indexes[0:len(indexes)*i/k]) + list(indexes[len(indexes)*(i+1)/k:])\n",
    "            test_indexes = indexes[len(indexes)*i/k:len(indexes)*(i+1)/k]\n",
    "        \n",
    "            model = model_factory().fit(x_local.iloc[train_indexes,:], y.iloc[train_indexes])\n",
    "            y_hat = model.predict(x_local)\n",
    "            score += model.score(x_local.iloc[test_indexes], y.iloc[test_indexes]) / k\n",
    "            y_hat_weighted = (model.predict_proba(x_local)[:,0] > prob_threshold)[test_indexes]\n",
    "            precision += (y.iloc[test_indexes][y_hat_weighted]).mean() / k\n",
    "            cm_accum += confusion_matrix(y.iloc[test_indexes], y_hat[test_indexes])\n",
    "            f1_accum += f1_score(y.iloc[test_indexes], y_hat[test_indexes], pos_label = 1) / k\n",
    "        \n",
    "        # but also test against the x_test\n",
    "        test_score = model.score(x_local_test[years_test == yr], y_test[years_test == yr])\n",
    "        test_y_hat = (model.predict_proba(x_local_test[years_test == yr])[:,0] > prob_threshold)\n",
    "        test_precision = y_test[years_test == yr][test_y_hat].mean()\n",
    "\n",
    "        print \"%d  score: %.3f  baseline: %.3f   prec: %.3f   f1: %.3f  | test score %.3f  prec %.3f\"  % (\n",
    "            yr, score, y[years==yr].mean(), precision, f1_accum, test_score, test_precision)\n",
    "        \n",
    "    return all_years_model;"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [amg1]",
   "language": "python",
   "name": "Python [amg1]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
