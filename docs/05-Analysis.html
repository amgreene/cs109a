<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Predicting Loan Outcomes</title>
  <link rel="stylesheet" type="text/css" href="cs109a.css">
</head>
<body>
<h1 style="text-align:center">Predicting Loan Outcomes using Machine Learning</h1>
  <div class='ournames'>
    <h3>David Modjeska and Andrew Greene</h3>
    <h4>CS109a: Introduction to Data Science<br>
    Harvard University, Autumn 2016</h4>
  </div>

<ul class='toc'>
 <li><a href='index.html'>Home</a></li>
 <li><a href='01-Context.html'>1. Initial Context</a></li>
 <li><a href='02-Collection.html'>2. Data Collection</a></li>
 <li><a href='03-Exploration.html'>3. Data Exploration</a></li>
 <li><a href='04-Modeling.html'>4. Data Modeling</a></li>
 <li><a href='05-Analysis.html'>5. Modeling Analysis</a></li>
</ul>

<h2>Part 5: Modeling Analysis</h2>

<p>In this part, we will compare the models developed in the part 4 with each other. On the basis of the strongest model(s), we will look at the predictors that most influence results.</p>

<p>We will also explore how participants in the Lending Club ecology have varying criteria for success. For example, the Lending Club institution wishes to improve their grading algorithm and set interest rates commensurate with risk. An individual investor, by contrast, wishes to minimize the likelihood of default. Alternatively, an investor may wish to maximize their total return, taking into account that a default often follows a history of partial payments, thereby generating positive revenue. Choosing an appropriate loss function affects selection of the most successful model, which is the focus of this final report part.</p>


<h3>Summary comparison of all models:</h3>

<p>The following table and bar charts compare all of the models in our notebook. For most metrics, we take as a baseline the balanced cross-validated logistic regression model, which has an AUC of 0.657, a test F1 of 0.534, and a test precision of 0.781. For classification accuracy, we take as a baseline the .848 rate resulting from the "Always 1" model (as well as all of the unbalanced models). <em>In each case, results that surpass our benchmark are highlighted in red.</em></p>
  
<p>Note that in cases where we optimized model hyperparameters using a grid of values, only the optimal hyperparameters are represented in this report.</p>

<p>Two groups of models stand out for performance:</p>

  <ul>
<li>The <b>Support Vector Classifier</b> (with an RBF kernel) has the highest AUC overall, at 0.666, irregardless of hyperparameter value. <i>C</i>. This model group does not do particularly well with metrics other than AUC, however. SVC performance lets us improve precision with the lowest cost in recall; but based on F1 and accuracy scores in the test data, this model group doesn't start with a strong minimum. (Given additional research time, we would also experiment with <i>gamma</i> values, which might improve performance further.)</li>

<li>The <b>Gradient Booster Classifier</b> group of models are competitive in AUC for some hyperparameter values. With 100 estimators, the AUC range is 0.659--0.662; with 500 estimators, the result is as high as 0.664. These results almost match those from SVC -- it is possible that additional estimators could give GBC an edge over SVC.</li>
  </ul>
  
<p>Some other model groups exceed the baseline in some way, but they have weaknesses that may undercut their usefulness in general:</p>

  <ul>
<li>The <b>Decision Tree Classifier</b> models scored well vis-a-vis precision on the test set, but were weak in other measures. Given that we have aimed to maximize precision, these models are worth considering.</li>

<li>Some <b>polynomial balanced Logistic Regression Classifiers with limited feature inputs</b> have high test F1 and precision scores, but low AUC and low test classification accuracy.</li>

  <li>Some <b>NLP</b> models did well in the F1 and overall scores of the test set; but because the NLP models represent only a loan subset, with different default properties and frequencies, we cannot directly compare these results to the baselines.</li>
  </ul>
  
<p><em>In summary, using AUC as our metric, the SVC and GBC models outperform the baseline model by about the same amount -- each with an AUC around 0.666, compared to 0.657 for the baseline model.</em> Both SVC and GBC models have reasonable but not excellent values for other metrics.</p>

<p><a href="#continued_1">[Skip to ROC Area Under Curve]</a></p>

  <p style="margin-left:5%;"><em> Red cells indicate results exceeding baseline.</em></p>
  
<div class='summary_table'>
<a></a><a></a><table><thead><tr><th>Model</th>
<th>auc</th>
<th>f1</th>
<th>prec</th>
<th>score</th>
<th>test_f1</th>
<th>test_prec</th>
<th>test_score</th></tr></thead>
<tbody>
<tr><th>AdaBoost LR=0.001000 num_est=10000</th><td>0.637</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>AdaBoost LR=0.010000 num_est=1000</th><td>0.637</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>AdaBoost LR=0.100000 num_est=200</th><td>0.627</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>AdaBoost LR=0.500000 num_est=100</th><td>0.606</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.001</td><td>0.600</td><td>0.848</td></tr>
<tr><th>AdaBoost LR=1.000000 num_est=50</th><td>0.604</td><td>0.917</td><td>0.620</td><td>0.847</td><td>0.003</td><td>0.539</td><td>0.848</td></tr>
<tr><th>Always 1</th><td>0.500</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>DTC</th><td>0.543</td><td>0.792</td><td>0.813</td><td>0.674</td><td>0.441</td><td class='better'>0.815</td><td>0.650</td></tr>
<tr><th>DTC log2 balanced</th><td>0.584</td><td>0.709</td><td>0.813</td><td>0.585</td><td>0.523</td><td class='better'>0.808</td><td>0.598</td></tr>
<tr><th>DTC sqrt balanced</th><td>0.541</td><td>0.753</td><td>0.816</td><td>0.630</td><td>0.434</td><td class='better'>0.812</td><td>0.655</td></tr>
<tr><th>GBC</th><td>0.629</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/2/0.010000</th><td>0.586</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/2/0.100000</th><td>0.629</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/3/0.010000</th><td>0.597</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/3/0.100000</th><td>0.638</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/4/0.010000</th><td>0.597</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/4/0.100000</th><td>0.641</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/5/0.010000</th><td>0.606</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/5/0.100000</th><td>0.642</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.500</td><td>0.848</td></tr>
<tr><th>GBC 10/6/0.010000</th><td>0.607</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/6/0.100000</th><td>0.642</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.643</td><td>0.848</td></tr>
<tr><th>GBC 10/7/0.010000</th><td>0.606</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/7/0.100000</th><td>0.641</td><td>0.917</td><td>0.800</td><td>0.847</td><td>0.001</td><td>0.636</td><td>0.848</td></tr>
<tr><th>GBC 10/8/0.010000</th><td>0.602</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/8/0.100000</th><td>0.637</td><td>0.917</td><td>0.700</td><td>0.848</td><td>0.001</td><td>0.605</td><td>0.848</td></tr>
<tr><th>GBC 10/9/0.010000</th><td>0.597</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 10/9/0.100000</th><td>0.632</td><td>0.917</td><td>0.715</td><td>0.847</td><td>0.003</td><td>0.673</td><td>0.848</td></tr>
<tr><th>GBC 100/2/0.010000</th><td>0.629</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 100/2/0.100000</th><td class='better'>0.659</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.471</td><td>0.848</td></tr>
<tr><th>GBC 100/3/0.010000</th><td>0.638</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 100/3/0.100000</th><td class='better'>0.662</td><td>0.918</td><td>0.467</td><td>0.848</td><td>0.002</td><td>0.588</td><td>0.848</td></tr>
<tr><th>GBC 100/4/0.010000</th><td>0.641</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 100/4/0.100000</th><td class='better'>0.661</td><td>0.917</td><td>0.562</td><td>0.847</td><td>0.004</td><td>0.550</td><td>0.848</td></tr>
<tr><th>GBC 100/5/0.010000</th><td>0.645</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 100/5/0.100000</th><td class='better'>0.659</td><td>0.916</td><td>0.641</td><td>0.846</td><td>0.009</td><td>0.618</td><td>0.847</td></tr>
<tr><th>GBC 100/6/0.010000</th><td>0.645</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.333</td><td>0.848</td></tr>
<tr><th>GBC 100/6/0.100000</th><td>0.654</td><td>0.915</td><td>0.682</td><td>0.845</td><td>0.012</td><td>0.641</td><td>0.846</td></tr>
<tr><th>GBC 100/7/0.010000</th><td>0.645</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.571</td><td>0.848</td></tr>
<tr><th>GBC 100/7/0.100000</th><td>0.650</td><td>0.915</td><td>0.688</td><td>0.843</td><td>0.016</td><td>0.661</td><td>0.845</td></tr>
<tr><th>GBC 100/8/0.010000</th><td>0.642</td><td>0.918</td><td>0.733</td><td>0.848</td><td>0.000</td><td>0.609</td><td>0.848</td></tr>
<tr><th>GBC 100/8/0.100000</th><td>0.645</td><td>0.915</td><td>0.704</td><td>0.843</td><td>0.020</td><td>0.698</td><td>0.843</td></tr>
<tr><th>GBC 100/9/0.010000</th><td>0.639</td><td>0.918</td><td>0.750</td><td>0.848</td><td>0.001</td><td>0.550</td><td>0.848</td></tr>
<tr><th>GBC 100/9/0.100000</th><td>0.641</td><td>0.913</td><td>0.703</td><td>0.841</td><td>0.023</td><td>0.692</td><td>0.843</td></tr>
<tr><th>GBC 20/2/0.010000</th><td>0.596</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/2/0.100000</th><td>0.642</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/3/0.010000</th><td>0.615</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/3/0.100000</th><td>0.648</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/4/0.010000</th><td>0.620</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/4/0.100000</th><td>0.649</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.600</td><td>0.848</td></tr>
<tr><th>GBC 20/5/0.010000</th><td>0.622</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/5/0.100000</th><td>0.650</td><td>0.918</td><td>0.443</td><td>0.848</td><td>0.000</td><td>0.471</td><td>0.848</td></tr>
<tr><th>GBC 20/6/0.010000</th><td>0.623</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 20/6/0.100000</th><td>0.651</td><td>0.917</td><td>0.733</td><td>0.847</td><td>0.001</td><td>0.544</td><td>0.848</td></tr>
<tr><th>GBC 200/2/0.010000</th><td>0.642</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 200/2/0.100000</th><td class='better'>0.663</td><td>0.918</td><td>0.468</td><td>0.848</td><td>0.001</td><td>0.562</td><td>0.848</td></tr>
<tr><th>GBC 200/3/0.010000</th><td>0.648</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 200/3/0.100000</th><td class='better'>0.663</td><td>0.917</td><td>0.554</td><td>0.847</td><td>0.004</td><td>0.592</td><td>0.848</td></tr>
<tr><th>GBC 200/4/0.010000</th><td>0.651</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 200/4/0.100000</th><td class='better'>0.660</td><td>0.916</td><td>0.613</td><td>0.846</td><td>0.009</td><td>0.624</td><td>0.847</td></tr>
<tr><th>GBC 200/5/0.010000</th><td>0.652</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>0.500</td><td>0.848</td></tr>
<tr><th>GBC 200/5/0.100000</th><td>0.656</td><td>0.916</td><td>0.638</td><td>0.845</td><td>0.015</td><td>0.635</td><td>0.846</td></tr>
<tr><th>GBC 200/6/0.010000</th><td>0.653</td><td>0.917</td><td>0.853</td><td>0.847</td><td>0.000</td><td>0.500</td><td>0.848</td></tr>
<tr><th>GBC 200/6/0.100000</th><td>0.649</td><td>0.914</td><td>0.677</td><td>0.843</td><td>0.020</td><td>0.657</td><td>0.844</td></tr>
<tr><th>GBC 200/7/0.010000</th><td>0.651</td><td>0.917</td><td>0.737</td><td>0.847</td><td>0.001</td><td>0.652</td><td>0.848</td></tr>
<tr><th>GBC 200/7/0.100000</th><td>0.646</td><td>0.913</td><td>0.712</td><td>0.841</td><td>0.023</td><td>0.680</td><td>0.843</td></tr>
<tr><th>GBC 200/8/0.010000</th><td>0.650</td><td>0.917</td><td>0.708</td><td>0.847</td><td>0.002</td><td>0.615</td><td>0.848</td></tr>
<tr><th>GBC 200/8/0.100000</th><td>0.639</td><td>0.913</td><td>0.698</td><td>0.841</td><td>0.027</td><td>0.684</td><td>0.842</td></tr>
<tr><th>GBC 200/9/0.010000</th><td>0.646</td><td>0.917</td><td>0.735</td><td>0.847</td><td>0.005</td><td>0.672</td><td>0.847</td></tr>
<tr><th>GBC 200/9/0.100000</th><td>0.633</td><td>0.914</td><td>0.677</td><td>0.842</td><td>0.027</td><td>0.685</td><td>0.842</td></tr>
<tr><th>GBC 50/2/0.010000</th><td>0.615</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/2/0.100000</th><td>0.654</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/3/0.010000</th><td>0.631</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/3/0.100000</th><td class='better'>0.658</td><td>0.918</td><td>0.350</td><td>0.848</td><td>0.000</td><td>0.474</td><td>0.848</td></tr>
<tr><th>GBC 50/4/0.010000</th><td>0.634</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/4/0.100000</th><td class='better'>0.659</td><td>0.917</td><td>0.633</td><td>0.848</td><td>0.001</td><td>0.487</td><td>0.848</td></tr>
<tr><th>GBC 50/5/0.010000</th><td>0.639</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/5/0.100000</th><td class='better'>0.658</td><td>0.917</td><td>0.612</td><td>0.847</td><td>0.004</td><td>0.567</td><td>0.848</td></tr>
<tr><th>GBC 50/6/0.010000</th><td>0.640</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/6/0.100000</th><td>0.656</td><td>0.916</td><td>0.680</td><td>0.846</td><td>0.007</td><td>0.607</td><td>0.847</td></tr>
<tr><th>GBC 50/7/0.010000</th><td>0.638</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/7/0.100000</th><td>0.652</td><td>0.916</td><td>0.737</td><td>0.845</td><td>0.010</td><td>0.647</td><td>0.846</td></tr>
<tr><th>GBC 50/8/0.010000</th><td>0.636</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/8/0.100000</th><td>0.648</td><td>0.916</td><td>0.676</td><td>0.845</td><td>0.013</td><td>0.642</td><td>0.846</td></tr>
<tr><th>GBC 50/9/0.010000</th><td>0.633</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 50/9/0.100000</th><td>0.642</td><td>0.915</td><td>0.655</td><td>0.844</td><td>0.017</td><td>0.679</td><td>0.844</td></tr>
<tr><th>GBC 500/2/0.010000</th><td>0.654</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>GBC 500/2/0.100000</th><td class='better'>0.664</td><td>0.917</td><td>0.603</td><td>0.847</td><td>0.005</td><td>0.633</td><td>0.848</td></tr>
<tr><th>GBC 500/3/0.010000</th><td class='better'>0.658</td><td>0.918</td><td>0.233</td><td>0.848</td><td>0.000</td><td>0.308</td><td>0.848</td></tr>
<tr><th>GBC 500/3/0.100000</th><td class='better'>0.660</td><td>0.916</td><td>0.635</td><td>0.845</td><td>0.011</td><td>0.632</td><td>0.846</td></tr>
<tr><th>GBC 500/4/0.010000</th><td class='better'>0.660</td><td>0.918</td><td>0.550</td><td>0.848</td><td>0.001</td><td>0.508</td><td>0.848</td></tr>
<tr><th>GBC 500/4/0.100000</th><td>0.653</td><td>0.914</td><td>0.635</td><td>0.843</td><td>0.020</td><td>0.672</td><td>0.844</td></tr>
<tr><th>GBC 500/5/0.010000</th><td class='better'>0.661</td><td>0.917</td><td>0.641</td><td>0.847</td><td>0.002</td><td>0.596</td><td>0.848</td></tr>
<tr><th>GBC 500/5/0.100000</th><td>0.647</td><td>0.913</td><td>0.691</td><td>0.840</td><td>0.026</td><td>0.668</td><td>0.843</td></tr>
<tr><th>GBC 500/6/0.010000</th><td class='better'>0.659</td><td>0.917</td><td>0.693</td><td>0.847</td><td>0.004</td><td>0.598</td><td>0.848</td></tr>
<tr><th>GBC 500/6/0.100000</th><td>0.638</td><td>0.911</td><td>0.712</td><td>0.838</td><td>0.031</td><td>0.679</td><td>0.841</td></tr>
<tr><th>GBC 500/7/0.010000</th><td>0.657</td><td>0.916</td><td>0.679</td><td>0.846</td><td>0.006</td><td>0.608</td><td>0.848</td></tr>
<tr><th>GBC 500/7/0.100000</th><td>0.630</td><td>0.911</td><td>0.704</td><td>0.838</td><td>0.035</td><td>0.705</td><td>0.840</td></tr>
<tr><th>GBC 500/8/0.010000</th><td>0.654</td><td>0.916</td><td>0.653</td><td>0.846</td><td>0.008</td><td>0.633</td><td>0.847</td></tr>
<tr><th>GBC 500/8/0.100000</th><td>0.625</td><td>0.912</td><td>0.711</td><td>0.839</td><td>0.032</td><td>0.692</td><td>0.841</td></tr>
<tr><th>GBC 500/9/0.010000</th><td>0.651</td><td>0.916</td><td>0.719</td><td>0.845</td><td>0.010</td><td>0.644</td><td>0.846</td></tr>
<tr><th>GBC 500/9/0.100000</th><td>0.615</td><td>0.913</td><td>0.719</td><td>0.840</td><td>0.029</td><td>0.701</td><td>0.841</td></tr>
<tr><th>GBC RFC</th><td>0.496</td><td>0.925</td><td>nan</td><td>0.860</td><td>0.000</td><td>nan</td><td class='better'>0.863</td></tr>
<tr><th>GradientBoostingClassifier</th><td>0.613</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>LogReg</th><td>0.657</td><td>0.918</td><td>0.556</td><td>0.848</td><td>0.002</td><td>0.564</td><td>0.848</td></tr>
<tr><th>LogReg balanced .6</th><td>0.656</td><td>0.723</td><td>0.727</td><td>0.607</td><td>0.281</td><td>0.734</td><td>0.604</td></tr>
<tr><th>LogReg balanced C=0.1</th><td>0.657</td><td>0.721</td><td>0.781</td><td>0.605</td><td>0.530</td><td>0.782</td><td>0.603</td></tr>
<tr><th>LogReg balanced C=1</th><td>0.656</td><td>0.723</td><td>0.780</td><td>0.607</td><td>0.529</td><td>0.782</td><td>0.604</td></tr>
<tr><th>LogReg balanced C=15</th><td>0.655</td><td>0.723</td><td>0.780</td><td>0.607</td><td>0.529</td><td>0.782</td><td>0.603</td></tr>
<tr><th>LogReg balanced all x^2</th><td>0.656</td><td>0.745</td><td>0.788</td><td>0.627</td><td>0.504</td><td>0.778</td><td>0.623</td></tr>
<tr><th>LogReg balanced basic x^2</th><td>0.564</td><td>0.670</td><td>0.824</td><td>0.545</td><td class='better'>0.586</td><td class='better'>0.822</td><td>0.546</td></tr>
<tr><th>LogReg balanced basic x^3</th><td>0.564</td><td>0.659</td><td>0.824</td><td>0.535</td><td class='better'>0.593</td><td class='better'>0.823</td><td>0.539</td></tr>
<tr><th>LogReg balanced employ x^2</th><td>0.564</td><td>0.670</td><td>0.824</td><td>0.545</td><td class='better'>0.586</td><td class='better'>0.822</td><td>0.546</td></tr>
<tr><th>LogReg_CV</th><td>0.630</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>LogReg_CV balanced</th><td>0.657</td><td>0.723</td><td>0.781</td><td>0.607</td><td>0.534</td><td>0.782</td><td>0.600</td></tr>
<tr><th>LogReg_CV balanced w/subgrade</th><td>0.656</td><td>0.741</td><td>0.767</td><td>0.628</td><td>0.497</td><td>0.775</td><td>0.628</td></tr>
<tr><th>LogisticRegression</th><td>0.611</td><td>0.726</td><td>0.774</td><td>0.612</td><td>0.530</td><td>0.782</td><td>0.603</td></tr>
<tr><th>NLP PCA GBC</th><td>0.491</td><td>0.925</td><td>nan</td><td>0.860</td><td>0.000</td><td>nan</td><td class='better'>0.863</td></tr>
<tr><th>NLP PCA Log_Reg</th><td>0.500</td><td>0.924</td><td>0.793</td><td>0.860</td><td>0.001</td><td class='better'>0.857</td><td class='better'>0.862</td></tr>
<tr><th>NLP PCA Log_Reg balanced</th><td>0.500</td><td>0.658</td><td>0.858</td><td>0.524</td><td class='better'>0.607</td><td class='better'>0.861</td><td>0.524</td></tr>
<tr><th>NLP QDA</th><td>0.495</td><td>0.925</td><td>nan</td><td>0.860</td><td>0.000</td><td>nan</td><td class='better'>0.863</td></tr>
<tr><th>NLP RFC</th><td>0.498</td><td>0.716</td><td>0.860</td><td>0.582</td><td>0.533</td><td class='better'>0.865</td><td>0.582</td></tr>
<tr><th>NLP log_reg</th><td>0.500</td><td>0.925</td><td>nan</td><td>0.860</td><td>0.000</td><td>nan</td><td class='better'>0.863</td></tr>
<tr><th>NLP log_reg balanced</th><td>0.502</td><td>0.338</td><td>0.858</td><td>0.296</td><td class='better'>0.829</td><td class='better'>0.862</td><td>0.284</td></tr>
<tr><th>NLP log_reg balanced proba6</th><td>0.500</td><td>0.699</td><td>0.914</td><td>0.565</td><td>0.002</td><td class='better'>0.826</td><td>0.561</td></tr>
<tr><th>QDA</th><td>0.625</td><td>0.917</td><td>0.756</td><td>0.848</td><td>0.002</td><td>0.747</td><td>0.848</td></tr>
<tr><th>QuadraticDiscriminantAnalysis</th><td>0.578</td><td>0.798</td><td>0.796</td><td>0.684</td><td>0.396</td><td class='better'>0.801</td><td>0.680</td></tr>
<tr><th>RFC 5/300</th><td>0.648</td><td>0.918</td><td>nan</td><td>0.848</td><td>0.000</td><td>nan</td><td>0.848</td></tr>
<tr><th>RFC balanced</th><td>0.495</td><td>0.925</td><td>nan</td><td>0.860</td><td>0.000</td><td>nan</td><td class='better'>0.863</td></tr>
<tr><th>RFC balanced 2/sqrt/200</th><td>0.635</td><td>0.718</td><td>0.790</td><td>0.600</td><td>0.530</td><td class='better'>0.790</td><td>0.600</td></tr>
<tr><th>RFC balanced 3/sqrt/200</th><td>0.640</td><td>0.733</td><td>0.787</td><td>0.615</td><td>0.513</td><td class='better'>0.786</td><td>0.614</td></tr>
<tr><th>RFC balanced 4/sqrt/200</th><td>0.643</td><td>0.738</td><td>0.786</td><td>0.620</td><td>0.503</td><td>0.782</td><td>0.622</td></tr>
<tr><th>RFC balanced 5/300</th><td>0.647</td><td>0.750</td><td>0.782</td><td>0.633</td><td>0.487</td><td>0.778</td><td>0.633</td></tr>
<tr><th>RFC balanced 5/sqrt/200</th><td>0.647</td><td>0.749</td><td>0.782</td><td>0.632</td><td>0.487</td><td>0.779</td><td>0.633</td></tr>
<tr><th>RFC balanced 6/sqrt/200</th><td>0.647</td><td>0.761</td><td>0.778</td><td>0.645</td><td>0.471</td><td>0.776</td><td>0.644</td></tr>
<tr><th>RFC balanced 7/sqrt/200</th><td>0.650</td><td>0.775</td><td>0.773</td><td>0.661</td><td>0.450</td><td>0.771</td><td>0.659</td></tr>
<tr><th>RFC balanced 8/sqrt/200</th><td>0.650</td><td>0.789</td><td>0.769</td><td>0.677</td><td>0.425</td><td>0.768</td><td>0.674</td></tr>
<tr><th>RFC balanced 9/sqrt/200</th><td>0.650</td><td>0.806</td><td>0.760</td><td>0.698</td><td>0.399</td><td>0.762</td><td>0.691</td></tr>
<tr><th>RFC balanced ^2 to  4/200</th><td>0.643</td><td>0.750</td><td>0.781</td><td>0.634</td><td>0.489</td><td>0.781</td><td>0.631</td></tr>
<tr><th>RFC balanced ^2 to  5/200</th><td>0.645</td><td>0.762</td><td>0.779</td><td>0.646</td><td>0.473</td><td>0.777</td><td>0.642</td></tr>
<tr><th>RFC balanced ^2 to  6/200</th><td>0.648</td><td>0.777</td><td>0.773</td><td>0.663</td><td>0.449</td><td>0.771</td><td>0.659</td></tr>
<tr><th>RFC balanced ^2 to  7/200</th><td>0.649</td><td>0.791</td><td>0.768</td><td>0.679</td><td>0.425</td><td>0.767</td><td>0.675</td></tr>
<tr><th>RFC balanced ^2 to  8/200</th><td>0.650</td><td>0.807</td><td>0.763</td><td>0.698</td><td>0.401</td><td>0.762</td><td>0.690</td></tr>
<tr><th>RFC balanced ^2 to  9/200</th><td>0.649</td><td>0.824</td><td>0.754</td><td>0.719</td><td>0.368</td><td>0.757</td><td>0.708</td></tr>
<tr><th>RFC balanced ^3 to  4/200</th><td>0.645</td><td>0.748</td><td>0.782</td><td>0.631</td><td>0.491</td><td>0.780</td><td>0.630</td></tr>
<tr><th>RFC balanced ^3 to  5/200</th><td>0.646</td><td>0.758</td><td>0.779</td><td>0.642</td><td>0.477</td><td>0.779</td><td>0.639</td></tr>
<tr><th>RFC balanced ^3 to  6/200</th><td>0.649</td><td>0.772</td><td>0.774</td><td>0.658</td><td>0.453</td><td>0.773</td><td>0.656</td></tr>
<tr><th>RFC balanced ^3 to  7/200</th><td>0.650</td><td>0.789</td><td>0.768</td><td>0.677</td><td>0.430</td><td>0.768</td><td>0.671</td></tr>
<tr><th>RFC balanced ^3 to  8/200</th><td>0.650</td><td>0.805</td><td>0.763</td><td>0.696</td><td>0.402</td><td>0.762</td><td>0.689</td></tr>
<tr><th>RFC balanced ^3 to  9/200</th><td>0.649</td><td>0.823</td><td>0.755</td><td>0.718</td><td>0.364</td><td>0.756</td><td>0.711</td></tr>
<tr><th>RFC balanced ^4 to  4/200</th><td>0.643</td><td>0.746</td><td>0.783</td><td>0.629</td><td>0.490</td><td>0.780</td><td>0.631</td></tr>
<tr><th>RFC balanced ^4 to  5/200</th><td>0.646</td><td>0.758</td><td>0.779</td><td>0.642</td><td>0.480</td><td>0.779</td><td>0.638</td></tr>
<tr><th>RFC balanced ^4 to  6/200</th><td>0.648</td><td>0.772</td><td>0.775</td><td>0.658</td><td>0.451</td><td>0.773</td><td>0.657</td></tr>
<tr><th>RFC balanced ^4 to  7/200</th><td>0.649</td><td>0.789</td><td>0.769</td><td>0.677</td><td>0.431</td><td>0.768</td><td>0.671</td></tr>
<tr><th>RFC balanced ^4 to  8/200</th><td>0.650</td><td>0.806</td><td>0.763</td><td>0.697</td><td>0.396</td><td>0.762</td><td>0.692</td></tr>
<tr><th>RFC balanced ^4 to  9/200</th><td>0.649</td><td>0.823</td><td>0.756</td><td>0.718</td><td>0.365</td><td>0.756</td><td>0.710</td></tr>
<tr><th>RandomForestClassifier</th><td>0.611</td><td>0.726</td><td>0.774</td><td>0.612</td><td>0.530</td><td>0.782</td><td>0.603</td></tr>
<tr><th>SVC</th><td class='better'>0.666</td><td>0.724</td><td>0.317</td><td>0.608</td><td>0.001</td><td>0.564</td><td>0.609</td></tr>
<tr><th>SVC 0.01</th><td class='better'>0.666</td><td>0.724</td><td>0.317</td><td>0.608</td><td>0.001</td><td>0.564</td><td>0.609</td></tr>
<tr><th>SVC 0.0316227766017</th><td class='better'>0.666</td><td>0.724</td><td>0.317</td><td>0.608</td><td>0.001</td><td>0.564</td><td>0.609</td></tr>
<tr><th>SVC 0.1</th><td class='better'>0.666</td><td>0.724</td><td>0.317</td><td>0.608</td><td>0.001</td><td>0.564</td><td>0.609</td></tr>
<tr><th>SmallBusiness</th><td>0.507</td><td>0.911</td><td>0.763</td><td>0.838</td><td>0.034</td><td>0.761</td><td>0.838</td></tr>
<tr><th>Stack LogReg balanced (logreg)</th><td>0.502</td><td>0.918</td><td>0.556</td><td>0.848</td><td>0.002</td><td>0.564</td><td>0.848</td></tr>
<tr><th>Stack LogReg balanced (mixed)</th><td>0.536</td><td>0.808</td><td>0.807</td><td>0.693</td><td>0.375</td><td class='better'>0.815</td><td>0.689</td></tr>
<tr><th>Stack RF balanced (logreg)</th><td>0.502</td><td>0.733</td><td>0.602</td><td>0.706</td><td>0.002</td><td>0.564</td><td>0.848</td></tr>
<tr><th>Stack RF balanced (mixed)</th><td>0.547</td><td>0.803</td><td>0.808</td><td>0.687</td><td>0.389</td><td class='better'>0.822</td><td>0.679</td></tr>
<tr><th>Stack Tree balanced (logreg)</th><td>0.502</td><td>0.918</td><td>0.556</td><td>0.848</td><td>0.002</td><td>0.564</td><td>0.848</td></tr>
<tr><th>Stack Tree balanced (mixed)</th><td>0.540</td><td>0.805</td><td>0.808</td><td>0.690</td><td>0.374</td><td class='better'>0.815</td><td>0.689</td></tr>
</tbody></table>
</div>
<p><a href="#continued_2">[Skip to Test Classification Accuracy]</a></p>

  <a name='continued_1' />
  
<h4>ROC Area Under Curve</h4>

<p><img src="images/score_auc.png"  style="width: 90%;"></p>
<p><a href="#continued_3">[Skip to Test Precision]</a></p>

  <a name='continued_2' />
  
<h4>Test Classification Accuracy</h4>

<p><img src="images/score_test_score.png" style="width: 90%;"></p>
<p><a href="#continued_4">[Skip to Using Payback Ratio]</a></p>

  <a name='continued_3' />
  
<h4>Test Precision</h4>

<p><img src="images/score_test_prec.png" style="width: 90%;"></p>

<a name='continued_4' />
<h3>Using &ldquo;Payback Ratio&rdquo; to transform classification into regression</h3>

<p>The modelling outcome that we&rsquo;ve used thus far is a categorical one: a &ldquo;Fully Paid&rdquo; loan is assigned the label 1, and a loan that has defaulted is assigned the label 0. By replacing this outcome with a continuous &ldquo;payback ratio&rdquo; measure, we can investigate the use of regression techniques.</p>

<p>We define the payback ratio as follows: For any given loan, the amount that has been paid by the borrower is the sum of three data columns: &ldquo;total received principal&rdquo;, &ldquo;total received interest&rdquo;, and &ldquo;total received late fees&rdquo;. In addition, the amount that a borrower is expected to pay is the value in the &ldquo;installment&rdquo; column times the overall number of payments. We have previously filtered loans to 36-month terms earlier in this modeling pipeline. The ratio of &ldquo;actual payments&rdquo; / &ldquo;expected payments&rdquo; is the raw payback ratio. This ratio is compatible with category labels of 0 and 1: a loan that is paid as expected will result in &ldquo;1&rdquo; using both approaches, and a loan in which the borrower &ldquo;takes the money and runs&rdquo; will result in &ldquo;0&rdquo; with both approaches. </p>

<p>We will need to make one further adjustment. If a loan is paid off early, then the &ldquo;actual payments&rdquo; will be less than the &ldquo;expected payments&rdquo; but the time value of money will make up the difference -- since the loan was repaid early, the money can be reinvested, and no loss is incurred by the investor. Consequently, for loans that are &ldquo;Fully Paid&rdquo; we take the payment ratio to be 1, and it is only for written-off loans that we compute the actual payment ratio.</p>

<p>Having defined our continuous outcome, we can now employ linear regression (with various basis functions) for modelling. Our first attempt is with cross-validated Ridge regression, which gives a test R<sup>2</sup> of 0.036 -- not an encouraging result. (This is nevertheless much better than the result from unregularized linear regression, which gives a test R<sup>2</sup> of only 0.006. Cross-validated Lasso gives a test R<sup>2</sup> of 0.014.)</p>

<p>We try again with cross-terms and, for the continuous predictors, polynomial terms up to ninth degree -- all of these give increasingly negative values for the test R<sup>2</sup>.</p>

<p>Finally, we try using a cutoff to transform our linear regression model back to a classification problem. This approach does not perform well, with an AUC of 0.536:</p>

<p><img src="images/image17.png" style="width: 40%;"></p>

<h3>Modelling goals and success opportunities</h3>

<p>In Part 2 of this report, we discussed the problem posed by the selection bias in this data. In particular, because the corpus includes only approved loans, we cannot assess whether our model correctly reduces the proportion of false negatives. Consequently, the only way to improve our classification rate is to reduce the proportion of false positives. If that task were easy, the existing LC models would have already eliminated these false positives from the Kaggle data set. Our models have unfortunately little to offer Lending Club as an organization.</p>

<p>On the other hand, there is a relevant principle to follow: &ldquo;I don&rsquo;t have to outrun the bear, I only have to outrun you&rdquo;. Nate Silver makes a similar observation in his book <em>The Signal and The Noise</em> (Penguin, 2015). So we can definitely offer value to the individual Lending Club member. Say that a member wishes to invest an arbitrary amount of money, with a maximum established for the risk placed on any one loan. We can choose one of our models and use it to rank all available loans in order of probability of being paid in full. We can then allocate the maximum per-loan amount (or the remaining to-be-funded balance) on the top-ranked loans until the member&rsquo;s resources are fully allocated. This triage approach would serve as a sort of intermediary or para-advisor between Lending Club and the individual investor, sorting out complexity, reducing uncertainty, and increasing confidence in the process.</p>

<h3>Future Research</h3>

<p>Future research suggested by this work would proceed in two primary directions. Both of these directions are broadly investor-side. First, it would be useful to validate the benefit of priority ranking approved loans as a route to financial gain. This validation would likely lead to model refinements and perhaps tuning of the data science pipeline on the basis of investor feedback. Second, it would be highly useful to investigate the nature of unapproved loans with Lending Club. An external researcher might potentially obtain a large budget to deliberately fund loans with a high probability of default, in order to study their properties and to assess the model&rsquo;s true recall rate. By contrast, Lending Club itself might make data available for unfunded loans, sanitized with particular care. </p>

<p>More purely technical future research could be productive as well. For example, deep learning approaches (such as neural networks) could be investigated for their utility in extracting additional signal from the noisy LC data. As another example, additional external economic indicators could be examined, in case certain aspects of loan context would shed light on loan performance. In particular, deriving economic predictors from zip codes, analogous to our national economic indicators derived from loan issue date, could be a fruitful line of inquiry.</p>

</body>
