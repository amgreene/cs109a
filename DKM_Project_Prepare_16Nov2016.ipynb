{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A - Intro to Data Science: Project (WIP)\n",
    "## Predicting Loan Outcomes\n",
    "## Group: Andrew Greene and David Modjeska\n",
    "### Harvard University, Fall 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "import datetime\n",
    "\n",
    "import enchant\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.decomposition import TruncatedSVD as tSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.io import mmwrite\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### specify processed data files to generate - full/partial, partial %, and train/test\n",
    "### Note: this cell is present in both notebooks\n",
    "\n",
    "# load and clean full dataset?\n",
    "load_full = True\n",
    "\n",
    "# if not loading and cleaning full dataset, what sample percentage?\n",
    "sample_percent = 10\n",
    "\n",
    "if load_full:\n",
    "    pct_str = \"\"\n",
    "else: # not load_full\n",
    "    pct_str = str(sample_percent) + \"_pct\"\n",
    "    \n",
    "# use training or testing data to generate minor files?\n",
    "minor_use_train = False\n",
    "if minor_use_train:\n",
    "    mode_str = \"train\"\n",
    "else: # not minor_use_train\n",
    "    mode_str = \"test\"\n",
    "    \n",
    "### set intermediate file names\n",
    "dir_str = \"./intermediate_files/\"\n",
    "\n",
    "processed_data_train_file = dir_str + \"processed_data_\" + \"train\" + pct_str + \".json\"\n",
    "processed_data_test_file = dir_str + \"processed_data_\" + \"test\" + pct_str + \".json\"\n",
    "\n",
    "nlp_data_file = dir_str + \"nlp_data_\" + mode_str + pct_str + \".json\"\n",
    "term_freqs_file = dir_str + \"term_freqs_\" + mode_str + pct_str + \".mtx\"\n",
    "diff_terms_file = dir_str + \"diff_terms_\" + mode_str + pct_str + \".json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load CPI data (from https://fred.stlouisfed.org/series/CPIAUCSL/downloaddata)\n",
    "def load_cpi_data():\n",
    "    cpi_xls = pd.ExcelFile(\"datasets/CPIAUCSL.xls\")\n",
    "    cpi_sheet = cpi_xls.sheet_names[0]\n",
    "    cpi_df = cpi_xls.parse(cpi_sheet, header = None, skiprows = 55)\n",
    "    cpi_df.columns = ['date', 'cpi']\n",
    "    \n",
    "    return cpi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load GDP data (from https://fred.stlouisfed.org/series/GDP/downloaddata)\n",
    "def load_gdp_data():\n",
    "    gdp_xls = pd.ExcelFile(\"datasets/GDP.xls\")\n",
    "    gdp_sheet = gdp_xls.sheet_names[0]\n",
    "    gdp_df = gdp_xls.parse(gdp_sheet, header = None, skiprows = 20)\n",
    "    gdp_df.columns = ['date', 'gdp']\n",
    "    \n",
    "    return gdp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load unemployment data (from https://fred.stlouisfed.org/series/UNRATE/downloaddata)\n",
    "def load_unemploy_data():\n",
    "    unemploy_xls = pd.ExcelFile(\"datasets/UNRATE.xls\")\n",
    "    unemploy_sheet = unemploy_xls.sheet_names[0]\n",
    "    unemploy_df = unemploy_xls.parse(unemploy_sheet, header = None, skiprows = 25)\n",
    "    unemploy_df.columns = ['date', 'unemploy']\n",
    "\n",
    "    return unemploy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### load economic data\n",
    "\n",
    "econ_filename = \"econ_data.json\"\n",
    "\n",
    "if not op.isfile(econ_filename):\n",
    "    cpi_df = load_cpi_data()\n",
    "    gdp_df = load_gdp_data()\n",
    "    unemploy_df = load_unemploy_data()\n",
    "    \n",
    "    econ_data_2 = pd.merge(cpi_df, gdp_df, 'inner')\n",
    "    econ_data_3 = pd.merge(econ_data_2, unemploy_df, 'inner')\n",
    "    \n",
    "    econ_data_3.to_json(\"econ_data.json\", date_unit = 's')\n",
    "    \n",
    "econ_data_4 = pd.read_json(econ_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert UNIX timestamp to calendar quarter\n",
    "# FIX hack to adjust timezone with timedelta\n",
    "new_col = econ_data_4[\"date\"].copy()\n",
    "for index in range(econ_data_4.shape[0]):\n",
    "        new_col[index] = \\\n",
    "             (datetime.datetime.fromtimestamp(econ_data_4[\"date\"].values[index]) +\n",
    "            datetime.timedelta(hours = 5)).replace(hour = 0)\n",
    "econ_data_4['date'] = new_col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpi</th>\n",
       "      <th>date</th>\n",
       "      <th>gdp</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.68</td>\n",
       "      <td>1948-01-01 00:00:00</td>\n",
       "      <td>266.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.82</td>\n",
       "      <td>1948-04-01 00:00:00</td>\n",
       "      <td>272.9</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.07</td>\n",
       "      <td>1974-10-01 00:00:00</td>\n",
       "      <td>308.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>42.70</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1380.7</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>43.70</td>\n",
       "      <td>1952-10-01 00:00:00</td>\n",
       "      <td>1417.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cpi                 date     gdp  unemploy\n",
       "0    23.68  1948-01-01 00:00:00   266.2       3.4\n",
       "1    23.82  1948-04-01 00:00:00   272.9       3.9\n",
       "10   24.07  1974-10-01 00:00:00   308.5       5.0\n",
       "100  42.70  1995-04-01 00:00:00  1380.7       4.9\n",
       "101  43.70  1952-10-01 00:00:00  1417.6       5.0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ_data_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to select the columns of interest from the data set\n",
    "def Select_Data(data):\n",
    "    \n",
    "    # list columns to select\n",
    "    features_to_select = ['id', \"loan_status\", \"annual_inc\", \"earliest_cr_line\", \"delinq_2yrs\", \\\n",
    "                          \"emp_length\", \"home_ownership\", \"inq_last_6mths\", \"loan_amnt\", \\\n",
    "                         \"purpose\", \"open_acc\", \"total_acc\", \"term\", \"installment\", \\\n",
    "                         \"revol_bal\", \"sub_grade\", \"issue_d\", \"int_rate\", \\\n",
    "                          'mths_since_last_record', 'emp_title', 'addr_state', \\\n",
    "                          'initial_list_status', 'verification_status_joint', 'recoveries']\n",
    "    ratios_to_select = [\"dti\", \"revol_util\"]\n",
    "    text_to_select = [\"desc\"]\n",
    "\n",
    "    # concatenate selected columns\n",
    "    data_select = pd.concat(( \\\n",
    "                            data[features_to_select],\n",
    "                            data[ratios_to_select], \\\n",
    "                            data[text_to_select]), \\\n",
    "                            axis = 1)\n",
    "\n",
    "    # synthesize new columns, and drop temporary columns\n",
    "    monthly_inc = (data[\"annual_inc\"] / 12)\n",
    "    data_select[\"ipr\"] = data[\"installment\"] / monthly_inc # income to payment ratio\n",
    "    data_select[\"rir\"] = data[\"revol_bal\"] / monthly_inc # revolving to income ratio\n",
    "    data_select = data_select.drop(\"revol_bal\", axis = 1)\n",
    "    \n",
    "    # rename columns for legibility\n",
    "    data_select.columns = [\n",
    "        'id', \"loan_status\", \"annual_income\", \"earliest_credit\", \"delinq_2_yrs\", \\\n",
    "        \"employ_length\", \"home_owner\", \"inquiry_6_mos\", \"loan_amount\", \\\n",
    "        \"loan_purpose\", \"open_accounts\", \"total_accounts\", \"loan_term\", \"installment\", \\\n",
    "        \"loan_subgrade\", \"issue_date\", \"interest_rate\", \"months_since_last_record\", \\\n",
    "        \"employ_title\", \"address_state\", \"initial_list_status\", \"verif_status\", 'recoveries', \\\n",
    "        \"dti\", \"revol_util\", \"description\", \\\n",
    "        \"ipr\", \"rir\" \\\n",
    "    ]\n",
    "    \n",
    "    return data_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to filter the data set down to rows of interest\n",
    "def Filter_Data(data_select):\n",
    "    \n",
    "    # set flags for resolved loans\n",
    "    status_flags = (data_select[\"loan_status\"] == \"Fully Paid\") | \\\n",
    "                    (data_select[\"loan_status\"] == \"Charged Off\")\n",
    "\n",
    "    # set flags for date range of interest\n",
    "    earliest_date = pd.to_datetime(\"2008-01-01\")\n",
    "    issue_dates = pd.to_datetime(data_select[\"issue_date\"])\n",
    "    date_flags = (issue_dates > earliest_date)\n",
    "    \n",
    "    # set flags for 36-month loan terms\n",
    "    #term_flags = (data_select['loan_term'] == \" 36 months\")\n",
    "\n",
    "    # filter rows per flags of interest\n",
    "    data_filter = \\\n",
    "        data_select.ix[status_flags & date_flags, :].reset_index(drop = True)\n",
    "    \n",
    "    return data_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to clean data - recoding, retyping, pruning, and censoring\n",
    "def Clean_Data(data_filter):\n",
    "    data_clean = data_filter.copy()\n",
    "\n",
    "    # recode loan status as boolean: charged off = True\n",
    "    data_clean[\"loan_status\"] = data_clean[\"loan_status\"] == \"Charged Off\"\n",
    "\n",
    "    # recode loan subgrades from 1 (best) to 35 (worst)\n",
    "    num_grades = 5\n",
    "    grade = data_clean[\"loan_subgrade\"].str[0]\n",
    "    grade = (pd.DataFrame(ord(c) for c in grade) - ord('A')) * num_grades\n",
    "    sub_grade = data_clean[\"loan_subgrade\"].str[1].astype('int')\n",
    "    data_clean[\"loan_subgrade\"] =  grade + sub_grade\n",
    "\n",
    "    # convert earliest credit date to datetime\n",
    "    data_clean[\"earliest_credit\"] = pd.to_datetime(data_clean[\"earliest_credit\"])\n",
    "\n",
    "    # prune extra text in loan term \n",
    "    data_clean[\"loan_term\"] = data_clean[\"loan_term\"].str.strip()\n",
    "    data_clean[\"loan_term\"] = data_clean[\"loan_term\"].str.replace(\" months\", \"\")\n",
    "\n",
    "\n",
    "    # prune extra text in employment length, and right-censor\n",
    "    data_clean[\"employ_length\"] = data_clean[\"employ_length\"].str.replace(\" years*\", \"\")\n",
    "    data_clean[\"employ_length\"] = data_clean[\"employ_length\"].str.replace(\"10\\+\", \"10\")\n",
    "    data_clean[\"employ_length\"] = data_clean[\"employ_length\"].str.replace(\"< 1\", \"0\")\n",
    "    \n",
    "    # right-censor delinquencies and inquiries\n",
    "    data_clean[\"delinq_2_yrs\"] = np.clip(data_clean[\"delinq_2_yrs\"], 0, 2)\n",
    "    data_clean[\"inquiry_6_mos\"] = np.clip(data_clean[\"inquiry_6_mos\"], 0, 3)\n",
    "        \n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to clean data - filtering nuisance NaNs (not structural NaNs)\n",
    "def Clean_Data2(data_clean):\n",
    "    n, p = data_clean.shape\n",
    "    \n",
    "    # count nulls by column\n",
    "    col_nan_pct = data_clean.isnull().sum() / n\n",
    "    \n",
    "    # flag columns that have some nuisance nulls\n",
    "    cols_with_nans = (col_nan_pct > 0.0) & (col_nan_pct < 0.01)\n",
    "    \n",
    "    # flag rows that have some nuisance nulls in the flagged columns\n",
    "    rows_without_nans_flags = data_clean.ix[:, cols_with_nans].notnull()\n",
    "    \n",
    "    # index the flagged rows that contain some nuisance nulls\n",
    "    rows_without_nans_indexes = np.where(rows_without_nans_flags)\n",
    "    \n",
    "    # filter the data set to rows that contain no nuisance nulls\n",
    "    data_clean2 = data_clean.ix[rows_without_nans_indexes[0], :]\n",
    "    \n",
    "    return data_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to pre-process each data subset to get around memory limits\n",
    "def Prep_Data_Part(index, num_parts, file_prefix, data_all):\n",
    "    filename = file_prefix + str(index) + \".csv\"\n",
    "    \n",
    "    # pre-process new data part if the file doesn't already exist\n",
    "    if not op.isfile(filename):\n",
    "        n, p = data_all.shape\n",
    "        \n",
    "        # pre-process the row range for this data part, avoiding empty data subsets\n",
    "        start_row = index * (n / num_parts)\n",
    "        data_part = data_all.ix[range(start_row, start_row + (n / num_parts)), :]\n",
    "        if data_part.shape[0] > 0:\n",
    "            data_select = Select_Data(data_part)\n",
    "            data_filter = Filter_Data(data_select)\n",
    "            if data_filter.shape[0] > 0:\n",
    "                data_clean = Clean_Data(data_filter)\n",
    "                data_clean2 = Clean_Data2(data_clean)\n",
    "                data_clean2.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lending Club (LC) data (from https://www.kaggle.com/wendykan/lending-club-loan-data)\n",
    "# helper function to pre-process full data set and save new file, \n",
    "# or to read pre-processed file if it already exists\n",
    "# Note: this non-shared intermediate file is not split into train/test\n",
    "def Preprocess_Full_Dataset():\n",
    "    file_prefix = \"./data_parts/loan_clean_part\"\n",
    "    full_clean_data_file = \"loan_clean_data.csv\"\n",
    "    num_parts = 30\n",
    "\n",
    "    # pre-process data set and save result as new file\n",
    "    if not op.isfile(full_clean_data_file):\n",
    "\n",
    "        # pre-process and save part files\n",
    "        data_raw = pd.read_csv(\"loan.csv\")\n",
    "        for part in range(num_parts):\n",
    "            Prep_Data_Part(part, num_parts, file_prefix, data_raw)       \n",
    "\n",
    "        # read and concatenate part files\n",
    "        data = pd.DataFrame({})\n",
    "        for part in range(num_parts):\n",
    "            file_part = file_prefix + str(part) + \".csv\"\n",
    "            if op.isfile(file_part):\n",
    "                data_part = pd.read_csv(file_part)\n",
    "                data = pd.concat((data, data_part), axis = 0)\n",
    "\n",
    "        # save full file\n",
    "        data = data.reset_index(drop = True)\n",
    "        data.to_csv(full_clean_data_file, index = False)\n",
    "\n",
    "    # read pre-processed full data file\n",
    "    data = pd.read_csv(full_clean_data_file)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to pre-process sampled data set and save new file, \n",
    "# or to read pre-processed file if it already exists\n",
    "# Note: this non-shared intermediate file is not split into train/test\n",
    "def Preprocess_Sample_Dataset():\n",
    "    sample_clean_data_file = \"loan_clean_data_\" + str(sample_percent) + \"_pct.csv\"\n",
    "\n",
    "    # pre-process sample data set and save result as new file\n",
    "    if not op.isfile(sample_clean_data_file):\n",
    "        data_raw = pd.read_csv(\"loan.csv\")\n",
    "        data_sample, data_other = sk_split(data_raw, train_size = sample_percent / 100.0)\n",
    "        data_select = Select_Data(data_sample)\n",
    "        data_filter = Filter_Data(data_select)\n",
    "        data_clean = Clean_Data(data_filter)\n",
    "        data_clean2 = Clean_Data2(data_clean)\n",
    "        data_clean2.to_csv(sample_clean_data_file, index = False)\n",
    "\n",
    "    # read pre-processed sample data file\n",
    "    data_clean2 = pd.read_csv(sample_clean_data_file)\n",
    "        \n",
    "    return data_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create or load appropriate version of data set for analysis\n",
    "\n",
    "if load_full:\n",
    "    data = Preprocess_Full_Dataset()\n",
    "    \n",
    "else:\n",
    "    data = Preprocess_Sample_Dataset()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set boolean and string column data types\n",
    "data[\"loan_status\"] = data[\"loan_status\"].astype(bool)\n",
    "data[\"description\"] = data[\"description\"].astype('str')\n",
    "data[\"issue_date\"] = data[\"issue_date\"].astype('str') # for later conversion to datetime\n",
    "data[\"employ_title\"] = data[\"employ_title\"].astype('str')\n",
    "data[\"address_state\"] = data[\"address_state\"].astype('str')\n",
    "\n",
    "nan_flags = data[\"description\"].str.match(\"nan\")\n",
    "data.ix[nan_flags, \"description\"] = None\n",
    "\n",
    "# replace all numbers with a token\n",
    "data[\"description\"] = data[\"description\"].str.replace(\"[0-9]+\", \"_number_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of nulls in data set by column:\n",
      "\n",
      "id                               0\n",
      "loan_status                      0\n",
      "annual_income                    0\n",
      "earliest_credit                  0\n",
      "delinq_2_yrs                     0\n",
      "employ_length                    0\n",
      "home_owner                       0\n",
      "inquiry_6_mos                    0\n",
      "loan_amount                      0\n",
      "loan_purpose                     0\n",
      "open_accounts                    0\n",
      "total_accounts                   0\n",
      "loan_term                        0\n",
      "installment                      0\n",
      "loan_subgrade                    0\n",
      "issue_date                       0\n",
      "interest_rate                    0\n",
      "months_since_last_record    217958\n",
      "employ_title                     0\n",
      "address_state                    0\n",
      "initial_list_status              0\n",
      "verif_status                248445\n",
      "recoveries                       0\n",
      "dti                              0\n",
      "revol_util                       0\n",
      "description                 160615\n",
      "ipr                              0\n",
      "rir                              0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summarize nulls/NaNs in data columns\n",
    "# FIX - print only cols with nulls\n",
    "print\n",
    "print \"Count of nulls in data set by column:\\n\"\n",
    "print data.isnull().sum()\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new column for first day of quarter that contains issue date\n",
    "new_col = data[\"issue_date\"].copy()\n",
    "new_col.name = 'issue_quarter'\n",
    "for index in range(data.shape[0]):\n",
    "    new_col.iloc[index] = datetime.datetime.strptime(data[\"issue_date\"].values[index], \n",
    "                                                \"%b-%Y\").replace(day = 1)\n",
    "    quarter = (new_col.iloc[index].month - 1) // 3\n",
    "    new_col.iloc[index] = new_col.iloc[index].replace(month = (3 * quarter) + 1)\n",
    "data = pd.concat((data, new_col), axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248445, 29)\n"
     ]
    }
   ],
   "source": [
    "# join LC and economic data\n",
    "print data.shape\n",
    "data = data.merge(right = econ_data_4, how = 'inner', \n",
    "                  left_on = \"issue_quarter\", right_on = \"date\", \n",
    "                  left_index = True).reset_index(drop = True)\n",
    "data.drop('issue_quarter', axis = 1, inplace = True)\n",
    "data.drop('date', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize float columns\n",
    "float_cols = ['dti', 'revol_util', 'ipr', 'rir', 'cpi', 'gdp', 'unemploy']\n",
    "data[float_cols] = data[float_cols].astype(float)\n",
    "data[float_cols] = Preprocessing.normalize(data[float_cols]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>earliest_credit</th>\n",
       "      <th>delinq_2_yrs</th>\n",
       "      <th>employ_length</th>\n",
       "      <th>home_owner</th>\n",
       "      <th>inquiry_6_mos</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>verif_status</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>dti</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>description</th>\n",
       "      <th>ipr</th>\n",
       "      <th>rir</th>\n",
       "      <th>cpi</th>\n",
       "      <th>gdp</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501.0</td>\n",
       "      <td>False</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>RENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>Borrower added on _number_/_number_/_number_...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430.0</td>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1999-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>car</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.08</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>Borrower added on _number_/_number_/_number_...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>small_business</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863.0</td>\n",
       "      <td>False</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>1996-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>RENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>Borrower added on _number_/_number_/_number_...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075269.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2004-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id loan_status  annual_income earliest_credit  delinq_2_yrs  \\\n",
       "0  1077501.0       False        24000.0      1985-01-01           0.0   \n",
       "1  1077430.0        True        30000.0      1999-04-01           0.0   \n",
       "2  1077175.0       False        12252.0      2001-11-01           0.0   \n",
       "3  1076863.0       False        49200.0      1996-02-01           0.0   \n",
       "4  1075269.0       False        36000.0      2004-11-01           0.0   \n",
       "\n",
       "  employ_length home_owner  inquiry_6_mos  loan_amount    loan_purpose  \\\n",
       "0            10       RENT            1.0       5000.0     credit_card   \n",
       "1             0       RENT            3.0       2500.0             car   \n",
       "2            10       RENT            2.0       2400.0  small_business   \n",
       "3            10       RENT            1.0      10000.0           other   \n",
       "4             3       RENT            3.0       5000.0         wedding   \n",
       "\n",
       "     ...     verif_status  recoveries       dti  revol_util  \\\n",
       "0    ...              NaN        0.00  0.004445    0.013455   \n",
       "1    ...              NaN      117.08  0.000161    0.001511   \n",
       "2    ...              NaN        0.00  0.001402    0.015834   \n",
       "3    ...              NaN        0.00  0.003215    0.003376   \n",
       "4    ...              NaN        0.00  0.001801    0.004550   \n",
       "\n",
       "                                         description       ipr       rir  \\\n",
       "0    Borrower added on _number_/_number_/_number_...  0.000013  0.001097   \n",
       "1    Borrower added on _number_/_number_/_number_...  0.000004  0.000108   \n",
       "2                                               None  0.000013  0.000465   \n",
       "3    Borrower added on _number_/_number_/_number_...  0.000013  0.000220   \n",
       "4                                               None  0.000008  0.000427   \n",
       "\n",
       "        cpi       gdp  unemploy  \n",
       "0  0.021895  0.999659  0.001093  \n",
       "1  0.021897  0.999758  0.001093  \n",
       "2  0.021895  0.999633  0.001093  \n",
       "3  0.021897  0.999749  0.001093  \n",
       "4  0.021897  0.999748  0.001093  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>delinq_2_yrs</th>\n",
       "      <th>inquiry_6_mos</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>open_accounts</th>\n",
       "      <th>total_accounts</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>installment</th>\n",
       "      <th>loan_subgrade</th>\n",
       "      <th>...</th>\n",
       "      <th>months_since_last_record</th>\n",
       "      <th>verif_status</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>dti</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>ipr</th>\n",
       "      <th>rir</th>\n",
       "      <th>cpi</th>\n",
       "      <th>gdp</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.484450e+05</td>\n",
       "      <td>2.484450e+05</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30487.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>2.484450e+05</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "      <td>248445.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.154117e+07</td>\n",
       "      <td>7.241011e+04</td>\n",
       "      <td>0.210143</td>\n",
       "      <td>0.821739</td>\n",
       "      <td>13552.297088</td>\n",
       "      <td>10.930097</td>\n",
       "      <td>25.014957</td>\n",
       "      <td>41.319036</td>\n",
       "      <td>418.061126</td>\n",
       "      <td>11.171297</td>\n",
       "      <td>...</td>\n",
       "      <td>76.864664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.921232</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>1.146846e-05</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.020923</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.358097e+07</td>\n",
       "      <td>5.765466e+04</td>\n",
       "      <td>0.514727</td>\n",
       "      <td>0.968979</td>\n",
       "      <td>8109.436450</td>\n",
       "      <td>4.870852</td>\n",
       "      <td>11.721059</td>\n",
       "      <td>9.968206</td>\n",
       "      <td>244.505571</td>\n",
       "      <td>6.761935</td>\n",
       "      <td>...</td>\n",
       "      <td>28.649832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753.751969</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>6.040069e-06</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.473400e+04</td>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>16.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.790870e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019594</td>\n",
       "      <td>0.992349</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.452197e+06</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7300.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>240.020000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>6.848098e-06</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.180235e+06</td>\n",
       "      <td>6.200000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>365.230000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>1.061129e-05</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.020924</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.559154e+07</td>\n",
       "      <td>8.700000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18225.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>547.160000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>1.534597e-05</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.860466e+07</td>\n",
       "      <td>8.706582e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1424.570000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33520.270000</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.121802</td>\n",
       "      <td>6.533504e-05</td>\n",
       "      <td>0.016245</td>\n",
       "      <td>0.023216</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  annual_income   delinq_2_yrs  inquiry_6_mos  \\\n",
       "count  2.484450e+05   2.484450e+05  248445.000000  248445.000000   \n",
       "mean   1.154117e+07   7.241011e+04       0.210143       0.821739   \n",
       "std    1.358097e+07   5.765466e+04       0.514727       0.968979   \n",
       "min    5.473400e+04   3.000000e+03       0.000000       0.000000   \n",
       "25%    1.452197e+06   4.500000e+04       0.000000       0.000000   \n",
       "50%    6.180235e+06   6.200000e+04       0.000000       1.000000   \n",
       "75%    1.559154e+07   8.700000e+04       0.000000       1.000000   \n",
       "max    6.860466e+07   8.706582e+06       2.000000       3.000000   \n",
       "\n",
       "         loan_amount  open_accounts  total_accounts      loan_term  \\\n",
       "count  248445.000000  248445.000000   248445.000000  248445.000000   \n",
       "mean    13552.297088      10.930097       25.014957      41.319036   \n",
       "std      8109.436450       4.870852       11.721059       9.968206   \n",
       "min       500.000000       1.000000        2.000000      36.000000   \n",
       "25%      7300.000000       7.000000       16.000000      36.000000   \n",
       "50%     12000.000000      10.000000       23.000000      36.000000   \n",
       "75%     18225.000000      14.000000       32.000000      36.000000   \n",
       "max     35000.000000      76.000000      150.000000      60.000000   \n",
       "\n",
       "         installment  loan_subgrade      ...        months_since_last_record  \\\n",
       "count  248445.000000  248445.000000      ...                    30487.000000   \n",
       "mean      418.061126      11.171297      ...                       76.864664   \n",
       "std       244.505571       6.761935      ...                       28.649832   \n",
       "min        16.080000       1.000000      ...                        0.000000   \n",
       "25%       240.020000       6.000000      ...                             NaN   \n",
       "50%       365.230000      11.000000      ...                             NaN   \n",
       "75%       547.160000      16.000000      ...                             NaN   \n",
       "max      1424.570000      34.000000      ...                      129.000000   \n",
       "\n",
       "       verif_status     recoveries            dti     revol_util  \\\n",
       "count           0.0  248445.000000  248445.000000  248445.000000   \n",
       "mean            NaN     161.921232       0.002417       0.008003   \n",
       "std             NaN     753.751969       0.001118       0.003724   \n",
       "min             NaN       0.000000       0.000000       0.000000   \n",
       "25%             NaN       0.000000       0.001579       0.005284   \n",
       "50%             NaN       0.000000       0.002374       0.008145   \n",
       "75%             NaN       0.000000       0.003229       0.010837   \n",
       "max             NaN   33520.270000       0.005802       0.121802   \n",
       "\n",
       "                ipr            rir            cpi            gdp  \\\n",
       "count  2.484450e+05  248445.000000  248445.000000  248445.000000   \n",
       "mean   1.146846e-05       0.000393       0.020923       0.999738   \n",
       "std    6.040069e-06       0.000333       0.000697       0.000040   \n",
       "min    4.790870e-08       0.000000       0.019594       0.992349   \n",
       "25%    6.848098e-06       0.000175       0.020243       0.999715   \n",
       "50%    1.061129e-05       0.000321       0.020924       0.999744   \n",
       "75%    1.534597e-05       0.000525       0.021466       0.999765   \n",
       "max    6.533504e-05       0.016245       0.023216       0.999807   \n",
       "\n",
       "            unemploy  \n",
       "count  248445.000000  \n",
       "mean        0.000973  \n",
       "std         0.000132  \n",
       "min         0.000705  \n",
       "25%         0.000880  \n",
       "50%         0.000977  \n",
       "75%         0.001082  \n",
       "max         0.001244  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate description lengths in characters\n",
    "description_flags = data[\"description\"].notnull()\n",
    "descriptions = data.ix[description_flags, \"description\"]\n",
    "description_lengths = descriptions.str.len()\n",
    "data['desc_len'] = description_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### write data frame to intermediate file\n",
    "mask = np.random.rand(data.shape[0]) < 0.7\n",
    "data_train = data.iloc[mask, :]\n",
    "data_test = data.iloc[~mask, :]     \n",
    "\n",
    "if not op.isfile(processed_data_train_file):\n",
    "    data_train.to_json(processed_data_train_file, date_unit = 's')\n",
    "    \n",
    "if not op.isfile(processed_data_test_file):\n",
    "    data_test.to_json(processed_data_test_file, date_unit = 's')\n",
    "\n",
    "if minor_use_train:\n",
    "    data = data_train\n",
    "else: #not minor_use_train\n",
    "    data = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract and pre-process loan description and loan_status for NLP\n",
    "data_nlp = data.loc[description_flags, :].copy()\n",
    "data_nlp[\"description\"] = data_nlp[\"description\"].str.replace(\"Borrower.* > \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### set up stemming\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language = 'english', ignore_stopwords = True)\n",
    "analyzer = TfidfVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "def take(n, seq):\n",
    "    seq = iter(seq)\n",
    "    result = []\n",
    "    try:\n",
    "        for i in range(n):\n",
    "            result.append(seq.next())\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stem words in Description field\n",
    "for index in range(data_nlp.shape[0]):\n",
    "    data_nlp['description'].values[index] = \\\n",
    "        \" \".join(take(1000, stemmed_words(data_nlp['description'].values[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26053, 9148)\n"
     ]
    }
   ],
   "source": [
    "# create n-grams from loan description\n",
    "vectorizer = CountVectorizer(stop_words = 'english', ngram_range = (1, 1))\n",
    "desc_matrix = vectorizer.fit_transform(data_nlp['description'].values)\n",
    "n, p = desc_matrix.shape\n",
    "print desc_matrix.shape\n",
    "\n",
    "if not op.isfile(term_freqs_file):\n",
    "    mmwrite(term_freqs_file, desc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply SVD to document-term matrix\n",
    "tsvd = tSVD(n_components = 100)\n",
    "desc_matrix_reduce = tsvd.fit_transform(desc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_nlp['desc_matrix_reduce'] = desc_matrix_reduce[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of descriptions and terms: 26053 9148\n",
      "\n",
      "Sample terms:"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_number_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_number________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_number_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_number_acr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_number_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_number_apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_number_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_number_bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_number_bdrm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_number_bil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "0                 _number_\n",
       "1  _number________________\n",
       "2                _number_a\n",
       "3              _number_acr\n",
       "4               _number_am\n",
       "5              _number_apr\n",
       "6                _number_b\n",
       "7             _number_bath\n",
       "8             _number_bdrm\n",
       "9              _number_bil"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print descriptive information about n-grams\n",
    "feature_names = np.array(vectorizer.get_feature_names()).reshape(-1, 1)\n",
    "print \"Number of descriptions and terms:\", n, p\n",
    "print\n",
    "print \"Sample terms:\", \n",
    "pd.DataFrame(feature_names[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_nlp['desc_word_count'] = desc_matrix.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_nlp['vocab_count'] = (desc_matrix > 0).sum(axis=1)\n",
    "data_nlp['vocab_count_norm'] = data_nlp['vocab_count'] \\\n",
    "    / data_nlp['desc_len'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split term matrix into defaulted vs. fully repaid\n",
    "mask = data_nlp[\"loan_status\"].values == False\n",
    "bad_term_matrix = desc_matrix[mask]\n",
    "good_term_matrix = desc_matrix[~mask]\n",
    "\n",
    "all_term_dict = zip(vectorizer.get_feature_names(),\n",
    "    np.asarray(desc_matrix.sum(axis = 0)).ravel())\n",
    "all_term_dict_df = pd.DataFrame(all_term_dict).sort_values(by = [1], \\\n",
    "                                                                   ascending = False)\n",
    "bad_term_dict = zip(vectorizer.get_feature_names(),\n",
    "    np.asarray(bad_term_matrix.sum(axis = 0)).ravel())\n",
    "bad_term_dict_df = pd.DataFrame(bad_term_dict).sort_values(by = [1], \\\n",
    "                                                                   ascending = False)\n",
    "good_term_dict = zip(vectorizer.get_feature_names(),\n",
    "    np.asarray(good_term_matrix.sum(axis = 0)).ravel())\n",
    "good_term_dict_df = pd.DataFrame(good_term_dict).sort_values(by = [1], \\\n",
    "                                                                 ascending = False)\n",
    "\n",
    "top_bad_dict_df = bad_term_dict_df.iloc[:125, :]\n",
    "top_good_dict_df = good_term_dict_df.iloc[:125, :]\n",
    "\n",
    "bad_only_df = pd.DataFrame(list(set(top_bad_dict_df[0]) - set(top_good_dict_df[0])))\n",
    "good_only_df = pd.DataFrame(list(set(top_good_dict_df[0]) - set(top_bad_dict_df[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Frequent Terms in Descriptions of All Loans:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>br</td>\n",
       "      <td>30481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_number_</td>\n",
       "      <td>25421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>credit</td>\n",
       "      <td>17189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>loan</td>\n",
       "      <td>15962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>pay</td>\n",
       "      <td>15590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>card</td>\n",
       "      <td>15177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>debt</td>\n",
       "      <td>12712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>payment</td>\n",
       "      <td>9282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>consolid</td>\n",
       "      <td>8648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>month</td>\n",
       "      <td>6895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>year</td>\n",
       "      <td>6534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6535</th>\n",
       "      <td>rate</td>\n",
       "      <td>5235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>use</td>\n",
       "      <td>4633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8078</th>\n",
       "      <td>thank</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>time</td>\n",
       "      <td>3726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>high</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>help</td>\n",
       "      <td>3316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>like</td>\n",
       "      <td>3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>need</td>\n",
       "      <td>3035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>make</td>\n",
       "      <td>2966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1\n",
       "1053        br  30481\n",
       "0     _number_  25421\n",
       "2015    credit  17189\n",
       "4759      loan  15962\n",
       "5909       pay  15590\n",
       "1274      card  15177\n",
       "2187      debt  12712\n",
       "5929   payment   9282\n",
       "1814  consolid   8648\n",
       "5239     month   6895\n",
       "9102      year   6534\n",
       "6535      rate   5235\n",
       "8614       use   4633\n",
       "8078     thank   3904\n",
       "8177      time   3726\n",
       "3847      high   3687\n",
       "3820      help   3316\n",
       "4716      like   3147\n",
       "5416      need   3035\n",
       "4885      make   2966"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print\n",
    "print \"Most Frequent Terms in Descriptions of All Loans:\"\n",
    "all_term_dict_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Frequent Terms Only in Descriptions of Defaulted Loans:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>repay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>respons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>purpos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0      term\n",
       "1       end\n",
       "2    faster\n",
       "3       apr\n",
       "4     refin\n",
       "5     cover\n",
       "6     repay\n",
       "7    colleg\n",
       "8   student\n",
       "9   respons\n",
       "10   purpos"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print\n",
    "print \"Most Frequent Terms Only in Descriptions of Defaulted Loans:\"\n",
    "bad_only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Frequent Terms Only in Descriptions of Fully Repaid Loans:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elimin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appreci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>realli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>instead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>opportun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>investor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0     elimin\n",
       "1      insur\n",
       "2    appreci\n",
       "3      extra\n",
       "4       feel\n",
       "5       hard\n",
       "6     realli\n",
       "7    instead\n",
       "8   opportun\n",
       "9   investor\n",
       "10       day"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print\n",
    "print \"Most Frequent Terms Only in Descriptions of Fully Repaid Loans:\"\n",
    "good_only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### count misspellings\n",
    "\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "num_terms = all_term_dict_df.shape[0]\n",
    "misspellings = np.zeros(num_terms)\n",
    "for index in range(num_terms):\n",
    "    misspellings[index] = not d.check(all_term_dict_df.iloc[index, 0])\n",
    "\n",
    "desc_matrix_misspell = desc_matrix[:, misspellings > 0]\n",
    "data_nlp['misspell_count'] = desc_matrix_misspell.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_nlp['misspell_count_norm'] = data_nlp['misspell_count'] \\\n",
    "    / data_nlp['desc_len'].astype(float) \n",
    "\n",
    "if not op.isfile(nlp_data_file):\n",
    "    data_nlp.to_json(nlp_data_file, date_unit = 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>delinq_2_yrs</th>\n",
       "      <th>inquiry_6_mos</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>open_accounts</th>\n",
       "      <th>total_accounts</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>installment</th>\n",
       "      <th>loan_subgrade</th>\n",
       "      <th>...</th>\n",
       "      <th>cpi</th>\n",
       "      <th>gdp</th>\n",
       "      <th>unemploy</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>desc_matrix_reduce</th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>vocab_count_norm</th>\n",
       "      <th>misspell_count</th>\n",
       "      <th>misspell_count_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.605300e+04</td>\n",
       "      <td>2.605300e+04</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "      <td>26053.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.190570e+06</td>\n",
       "      <td>7.163811e+04</td>\n",
       "      <td>0.177676</td>\n",
       "      <td>0.837984</td>\n",
       "      <td>13240.314935</td>\n",
       "      <td>10.523126</td>\n",
       "      <td>24.140061</td>\n",
       "      <td>40.459525</td>\n",
       "      <td>411.167611</td>\n",
       "      <td>10.080451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021408</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>289.048286</td>\n",
       "      <td>1.920877</td>\n",
       "      <td>17.274786</td>\n",
       "      <td>14.461252</td>\n",
       "      <td>0.055646</td>\n",
       "      <td>8.774767</td>\n",
       "      <td>0.028010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.277653e+06</td>\n",
       "      <td>6.779411e+04</td>\n",
       "      <td>0.468513</td>\n",
       "      <td>0.980955</td>\n",
       "      <td>7810.900754</td>\n",
       "      <td>4.595003</td>\n",
       "      <td>11.309928</td>\n",
       "      <td>9.335126</td>\n",
       "      <td>239.414904</td>\n",
       "      <td>6.502705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>309.089185</td>\n",
       "      <td>3.187672</td>\n",
       "      <td>19.822992</td>\n",
       "      <td>12.898424</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>11.819930</td>\n",
       "      <td>0.016159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.724500e+04</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>16.080000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.659570e+05</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>232.870000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.723294</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.015544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.524583e+06</td>\n",
       "      <td>6.100000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>363.130000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021465</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1.080002</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.028369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.555013e+06</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18000.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>538.400000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021792</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>1.995462</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.039568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.304770e+07</td>\n",
       "      <td>7.141778e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1408.130000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023216</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>4517.000000</td>\n",
       "      <td>104.942106</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  annual_income  delinq_2_yrs  inquiry_6_mos   loan_amount  \\\n",
       "count  2.605300e+04   2.605300e+04  26053.000000   26053.000000  26053.000000   \n",
       "mean   3.190570e+06   7.163811e+04      0.177676       0.837984  13240.314935   \n",
       "std    3.277653e+06   6.779411e+04      0.468513       0.980955   7810.900754   \n",
       "min    5.724500e+04   4.000000e+03      0.000000       0.000000    500.000000   \n",
       "25%    9.659570e+05   4.500000e+04      0.000000       0.000000   7200.000000   \n",
       "50%    1.524583e+06   6.100000e+04      0.000000       1.000000  12000.000000   \n",
       "75%    4.555013e+06   8.500000e+04      0.000000       1.000000  18000.000000   \n",
       "max    1.304770e+07   7.141778e+06      2.000000       3.000000  35000.000000   \n",
       "\n",
       "       open_accounts  total_accounts     loan_term   installment  \\\n",
       "count   26053.000000    26053.000000  26053.000000  26053.000000   \n",
       "mean       10.523126       24.140061     40.459525    411.167611   \n",
       "std         4.595003       11.309928      9.335126    239.414904   \n",
       "min         1.000000        3.000000     36.000000     16.080000   \n",
       "25%         7.000000       16.000000     36.000000    232.870000   \n",
       "50%        10.000000       22.000000     36.000000    363.130000   \n",
       "75%        13.000000       31.000000     36.000000    538.400000   \n",
       "max        48.000000       91.000000     60.000000   1408.130000   \n",
       "\n",
       "       loan_subgrade         ...                    cpi           gdp  \\\n",
       "count   26053.000000         ...           26053.000000  26053.000000   \n",
       "mean       10.080451         ...               0.021408      0.999723   \n",
       "std         6.502705         ...               0.000504      0.000036   \n",
       "min         1.000000         ...               0.019942      0.999537   \n",
       "25%         6.000000         ...               0.021050      0.999699   \n",
       "50%         9.000000         ...               0.021465      0.999729   \n",
       "75%        14.000000         ...               0.021792      0.999751   \n",
       "max        34.000000         ...               0.023216      0.999789   \n",
       "\n",
       "           unemploy      desc_len  desc_matrix_reduce  desc_word_count  \\\n",
       "count  26053.000000  26053.000000        26053.000000     26053.000000   \n",
       "mean       0.001054    289.048286            1.920877        17.274786   \n",
       "std        0.000088    309.089185            3.187672        19.822992   \n",
       "min        0.000742      1.000000            0.000000         0.000000   \n",
       "25%        0.000977    119.000000            0.723294         7.000000   \n",
       "50%        0.001081    206.000000            1.080002        12.000000   \n",
       "75%        0.001139    341.000000            1.995462        22.000000   \n",
       "max        0.001244   4517.000000          104.942106       399.000000   \n",
       "\n",
       "        vocab_count  vocab_count_norm  misspell_count  misspell_count_norm  \n",
       "count  26053.000000      26053.000000    26053.000000         26053.000000  \n",
       "mean      14.461252          0.055646        8.774767             0.028010  \n",
       "std       12.898424          0.017765       11.819930             0.016159  \n",
       "min        0.000000          0.000000        0.000000             0.000000  \n",
       "25%        6.000000          0.046908        2.000000             0.015544  \n",
       "50%       11.000000          0.058824        6.000000             0.028369  \n",
       "75%       19.000000          0.066667       11.000000             0.039568  \n",
       "max      208.000000          0.181818      244.000000             0.157895  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nlp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NLP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@@ create TF-IDF term matrices for two loan outcomes separately\n",
    "\n",
    "# split data\n",
    "data_nlp_2 = data_nlp[['description', 'loan_status']]\n",
    "good_flags = data_nlp_2['loan_status'] == True\n",
    "good_nlp = data_nlp_2.loc[good_flags, :]\n",
    "bad_nlp = data_nlp_2.loc[~good_flags, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute matrices\n",
    "vectorizer_good = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 1), norm = None,\n",
    "                                 use_idf = True)\n",
    "vectorizer_bad = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 1), norm = None,\n",
    "                                use_idf = True)\n",
    "good_matrix = vectorizer_good.fit_transform(good_nlp['description'].values)\n",
    "bad_matrix = vectorizer_bad.fit_transform(bad_nlp['description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sum term scores\n",
    "good_term_scores = good_matrix.sum(axis = 0)\n",
    "bad_term_scores = bad_matrix.sum(axis = 0)\n",
    "\n",
    "good_term_scores = Preprocessing.normalize(good_term_scores, axis = 1)\n",
    "bad_term_scores = Preprocessing.normalize(bad_term_scores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get feature names\n",
    "good_terms = vectorizer_good.get_feature_names()\n",
    "bad_terms = vectorizer_bad.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### calculate absolute differences between normalized term scores\n",
    "\n",
    "n_good = len(good_terms)\n",
    "n_bad = len(bad_terms)\n",
    "\n",
    "good_diffs = np.zeros(n_good)\n",
    "bad_diffs = np.zeros(n_bad)\n",
    "\n",
    "# consider all words in good loans\n",
    "for good_term in range(n_good):\n",
    "    try: \n",
    "        match_index = bad_terms.index(good_terms[good_term])\n",
    "        good_diffs[good_term] = np.abs(good_term_scores[0, good_term] - \n",
    "                                       bad_term_scores[0, match_index])\n",
    "    except ValueError:\n",
    "        good_diffs[good_term] = np.abs(good_term_scores[0, good_term])\n",
    "\n",
    "# # only consider words uniquely in bad loans, since matches already considered above in loop\n",
    "for bad_term in range(n_bad):\n",
    "    try:\n",
    "        match_index = good_terms.index(bad_terms[bad_term])\n",
    "        bad_diffs[bad_term] = -1\n",
    "    except ValueError:\n",
    "        bad_diffs[bad_term] = np.abs(bad_term_scores[0, bad_term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diffs</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049409</td>\n",
       "      <td>_number_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>0.028628</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>0.025929</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.021223</td>\n",
       "      <td>busi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.018392</td>\n",
       "      <td>consolid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.018263</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.013572</td>\n",
       "      <td>br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.013375</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0.013276</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.012958</td>\n",
       "      <td>apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>0.012779</td>\n",
       "      <td>pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>0.011586</td>\n",
       "      <td>refin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.011056</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.010857</td>\n",
       "      <td>colleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>0.010849</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>0.010700</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.010272</td>\n",
       "      <td>improv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0.010169</td>\n",
       "      <td>employ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>0.010029</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>0.009582</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         diffs     terms\n",
       "0     0.049409  _number_\n",
       "2353  0.028628      need\n",
       "2812  0.025929      rate\n",
       "505   0.021223      busi\n",
       "763   0.018392  consolid\n",
       "1674  0.018263      help\n",
       "452   0.013572        br\n",
       "864   0.013375   current\n",
       "2550  0.013276   payment\n",
       "232   0.012958       apr\n",
       "2541  0.012779       pay\n",
       "2871  0.011586     refin\n",
       "544   0.011056       car\n",
       "674   0.010857    colleg\n",
       "3522  0.010849     thank\n",
       "2093  0.010700     lower\n",
       "1783  0.010272    improv\n",
       "1163  0.010169    employ\n",
       "3564  0.010029      time\n",
       "3229  0.009582     small"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### find top different terms\n",
    "\n",
    "good_diffs_df = pd.DataFrame({'diffs': good_diffs, 'terms': good_terms})\n",
    "bad_diffs_df = pd.DataFrame({'diffs': bad_diffs, 'terms': bad_terms})\n",
    "\n",
    "diffs_df = pd.concat((good_diffs_df, bad_diffs_df), axis = 0)\n",
    "diffs_df_sort = diffs_df.sort_values(by = 'diffs', ascending = False)\n",
    "diffs_df_sort.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### add term flags to data as new features\n",
    "\n",
    "num_top_diffs = 30\n",
    "diff_indexes = np.zeros(num_top_diffs).astype(int)\n",
    "for diff in range(num_top_diffs):\n",
    "    match_index = np.where(feature_names == diffs_df_sort.iloc[diff, 1])[0]\n",
    "    diff_indexes[diff] = match_index\n",
    "    \n",
    "count_cols = desc_matrix[:, diff_indexes]\n",
    "count_col_names = feature_names[diff_indexes, 0].astype(str)\n",
    "count_cols_df = pd.DataFrame(count_cols.toarray(), columns = count_col_names)\n",
    "if not op.isfile(diff_terms_file):\n",
    "    count_cols_df.to_json(diff_terms_file, date_unit = 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
