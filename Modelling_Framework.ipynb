{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "import datetime\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.cross_validation import KFold as kfold\n",
    "from sklearn.decomposition import TruncatedSVD as tSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import LogisticRegression as Log_Reg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from scipy.io import mmread\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') \n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_expected_profit(profit_data_test, test_y_hat):\n",
    "    interest_revenue = model_loan_term * profit_data_test.installment[test_y_hat == True].sum()\n",
    "    recoveries = recoveries_avg * (test_y_hat == False).sum()\n",
    "    principal_losses = profit_data_test.loan_amount[test_y_hat == False].sum()\n",
    "    profit_mm = round(interest_revenue + recoveries - principal_losses) / float(10 ** 6)\n",
    "    return profit_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_model_all_years(model_factory, columns = None, poly_degree = None, prob_threshold = 0.5, \n",
    "                         x = x_expanded, x_test = x_test_expanded, y = y, y_test = y_test,\n",
    "                        years = years, years_test = years_test, profit_data_test = profit_data_test):\n",
    "    k = 5\n",
    "    np.random.seed(1729)\n",
    "    \n",
    "    if columns is None:\n",
    "        x_local = x\n",
    "        x_local_test = x_test\n",
    "    else:\n",
    "        x_local = x[columns]\n",
    "        x_local_test = x_test[columns]\n",
    "        \n",
    "    if poly_degree is not None:\n",
    "        poly_xform = Preprocessing.PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "        x_local = pd.DataFrame(poly_xform.fit_transform(x_local))\n",
    "        x_local_test = pd.DataFrame(poly_xform.fit_transform(x_local_test))\n",
    "        \n",
    "    if True: # for yr in [2011, 2012, 2013]: # set(years.values):\n",
    "        indexes = range(len(years))\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "        cm_accum = np.zeros((2, 2))\n",
    "        f1_accum = 0\n",
    "        score = 0\n",
    "        weighted_score = 0\n",
    "\n",
    "        # k-fold cross-validation\n",
    "        for i in range(k):\n",
    "            train_indexes = list(indexes[0:len(indexes)*i/k]) + list(indexes[len(indexes)*(i+1)/k:])\n",
    "            test_indexes = indexes[len(indexes)*i/k:len(indexes)*(i+1)/k]\n",
    "        \n",
    "            #print \"TRAIN \", train_indexes\n",
    "            #print 'TEST', test_indexes\n",
    "            #print \"Y\", y.iloc[test_indexes]\n",
    "            \n",
    "            # model = model_factory().fit(x_expanded[years==yr], y[years==yr])\n",
    "            # score = model.score(x_expanded[years==yr], y[years==yr]) / k\n",
    "            model = model_factory().fit(x_local.iloc[train_indexes,:], y.iloc[train_indexes])\n",
    "            y_hat = model.predict(x_local)\n",
    "            score += model.score(x_local.iloc[test_indexes], y.iloc[test_indexes]) / k\n",
    "            y_hat_weighted = (model.predict_proba(x_local)[:,0] > prob_threshold)[test_indexes]\n",
    "            weighted_score += (y.iloc[test_indexes][y_hat_weighted]).mean() / k\n",
    "            cm_accum += confusion_matrix(y.iloc[test_indexes], y_hat[test_indexes])\n",
    "            f1_accum += f1_score(y.iloc[test_indexes], y_hat[test_indexes], pos_label = 1) / k\n",
    "        \n",
    "        # but also test against the x_test\n",
    "        test_y_hat = (model.predict_proba(x_local_test)[:,0] > prob_threshold)\n",
    "        test_score = (y_test == test_y_hat).mean()\n",
    "        test_precision = 1- y_test[test_y_hat].mean()\n",
    "        test_f1 = f1_score(y_test, test_y_hat, pos_label = 1)\n",
    "\n",
    "        # expected profit\n",
    "        profit_mm = calc_expected_profit(profit_data_test, test_y_hat)\n",
    "        \n",
    "        print \"%d  score: %.3f  baseline: %.3f   wscore: %.3f   f1: %.3f  | test score %.3f  1-prec %.3f f1 %.3f  GP %dMM\" \\\n",
    "        % (0, score, 1-y.mean(), 1-weighted_score, f1_accum, test_score, test_precision, test_f1, profit_mm)\n",
    "\n",
    "# TODO: Confusion matrix (right now, we're not doing well enough to worry about that)\n",
    "# TODO: Pretty-print\n",
    "# TODO: Store results to allow side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_model_by_year(model_factory, columns = None, prob_threshold = 0.5,\n",
    "                        x = x_expanded, x_test = x_test_expanded, y = y, y_test = y_test,\n",
    "                        years = years, years_test = years_test, profit_data_test = profit_data_test):\n",
    "    eval_model_all_years(model_factory, columns, None, prob_threshold, x, x_test, y, y_test, years, years_test,\n",
    "                        profit_data_test)\n",
    "    k = 5\n",
    "    np.random.seed(1729)\n",
    "    \n",
    "    if columns is None:\n",
    "        x_local = x\n",
    "        x_local_test = x_test\n",
    "    else:\n",
    "        x_local = x[columns]\n",
    "        x_local_test = x_test[columns]\n",
    "        \n",
    "    for yr in [2011, 2012, 2013]: # set(years.values):\n",
    "        indexes = np.where(years == yr)[0]\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "        cm_accum = np.zeros((2, 2))\n",
    "        f1_accum = 0\n",
    "        score = 0\n",
    "        weighted_score = 0\n",
    "\n",
    "        # k-fold cross-validation\n",
    "        for i in range(k):\n",
    "            train_indexes = list(indexes[0:len(indexes)*i/k]) + list(indexes[len(indexes)*(i+1)/k:])\n",
    "            test_indexes = indexes[len(indexes)*i/k:len(indexes)*(i+1)/k]\n",
    "        \n",
    "            #print \"TRAIN \", train_indexes\n",
    "            #print 'TEST', test_indexes\n",
    "            #print \"Y\", y.iloc[test_indexes]\n",
    "            \n",
    "            # model = model_factory().fit(x_expanded[years==yr], y[years==yr])\n",
    "            # score = model.score(x_expanded[years==yr], y[years==yr]) / k\n",
    "            model = model_factory().fit(x_local.iloc[train_indexes,:], y.iloc[train_indexes])\n",
    "            y_hat = model.predict(x_local)\n",
    "            score += model.score(x_local.iloc[test_indexes], y.iloc[test_indexes]) / k\n",
    "            y_hat_weighted = (model.predict_proba(x_local)[:,0] > prob_threshold)[test_indexes]\n",
    "            weighted_score += (y.iloc[test_indexes][y_hat_weighted]).mean() / k\n",
    "            cm_accum += confusion_matrix(y.iloc[test_indexes], y_hat[test_indexes])\n",
    "            f1_accum += f1_score(y.iloc[test_indexes], y_hat[test_indexes], pos_label = 1) / k\n",
    "        \n",
    "        # but also test against the x_test\n",
    "        test_score = model.score(x_local_test[years_test == yr], y_test[years_test == yr])\n",
    "        test_y_hat = (model.predict_proba(x_local_test[years_test == yr])[:,0] > prob_threshold)\n",
    "        test_precision = 1- y_test[years_test == yr][test_y_hat].mean()\n",
    "\n",
    "        print \"%d  score: %.3f  baseline: %.3f   wscore: %.3f   f1: %.3f  | test score %.3f  1-prec %.3f\"  % (\n",
    "            yr, score, 1-y[years==yr].mean(), 1-weighted_score, f1_accum, test_score, test_precision)\n",
    "\n",
    "# TODO: Confusion matrix (right now, we're not doing well enough to worry about that)\n",
    "# TODO: Pretty-print\n",
    "# TODO: Store results to allow side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_model_with_threshold(model_factory, columns=None):\n",
    "    k = 5\n",
    "    np.random.seed(1729)\n",
    "    if columns is None:\n",
    "        x_local = x_expanded\n",
    "    else:\n",
    "        x_local = x_expanded[columns]\n",
    "\n",
    "    if True: # because old indent for loop\n",
    "        indexes = range(len(y))\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "        probs = np.ones_like(y) * -1\n",
    "\n",
    "        for i in range(k):\n",
    "            train_indexes = list(indexes[0:len(indexes)*i/k]) + list(indexes[len(indexes)*(i+1)/k:])\n",
    "            test_indexes = indexes[len(indexes)*i/k:len(indexes)*(i+1)/k]\n",
    "        \n",
    "            model = model_factory().fit(x_local.iloc[train_indexes,:], y.iloc[train_indexes])\n",
    "            probs_test = (model.predict_proba(x_local)[:,0]) #[test_indexes]\n",
    "            probs = np.where([ii in test_indexes for ii in range(len(y))],  # slow but the only one I've found that works!\n",
    "                             probs_test, probs)\n",
    "            # print i, (probs == -1).sum(), (probs > 0).sum()\n",
    "            \n",
    "    thresholds = np.arange(0, 1, 0.05)\n",
    "    plt.plot(thresholds,\n",
    "             [1-y[probs > t].mean() for t in thresholds])\n",
    "    plt.show()\n",
    "\n",
    "    return probs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
