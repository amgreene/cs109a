% otftotfm -a -e ec -fkern FRAMDCN.TTF FGothicCond
\input eplain
\pdfpageheight=11in
\pdfpagewidth=8.5in
\frenchspacing
\def\sp#1{^{(#1)}}
\parskip=0pt
\parindent=2em
\overfullrule=0pt
\def\prepic{\vskip-\baselineskip}
\def\prepicsm{\vskip-8pt\relax}
\def\prepiclg{\vskip-15pt\relax}
\def\pic#1#2{\pdfximage width #1 {#2}\pdfrefximage\pdflastximage}
\def\picbox#1#2{\hbox{\pic{#1}{#2}}}
\def\pics#1#2{\hbox{\hskip -.15in \pic{1.7in}{#1stdev1#2.png}\pic{1.7in}{#1stdev2#2.png}\pic{1.7in}{#1stdev4#2.png}\pic{1.7in}{#1nonsep#2.png}}}
\def\caption#1#2{\vtop{\noindent\ss{\ssbf #1} -- #2\hfil}}
\def\todo#1{{\bf TODO: #1}}
\def\hr{\vskip 2pt \hrule \vskip 2pt}
\def\tag#1{\noindent\vtop to 0pt{\llap{\sl (#1)\quad}\vss}\ignorespaces}
\def\hbarchart#1#2{\hbox{\relax
\hbox to 1cm{\hss\vrule height 8pt width #2cm}\relax
\vrule width .2pt height 10pt depth 2pt \relax
\hbox to 1cm{\vrule height 8pt width #1cm\hss}}}
\def\valbar#1{#1&\hbarchart{#1}{-#1}}
\font\ss=FranklinGothicBook at 10pt
\font\ssbf=FranklinGothicDemi at 10pt
\def\assignment#1{{\noindent \it #1\par}}
\def\sec#1{\vskip10pt\noindent{\bf #1}\par\penalty10000\vskip4pt\penalty10000\noindent\ignorespaces}
\def\*{\par\noindent\hangindent=2em\hangafter=1\hbox to 1em{\hfil}\hbox to 1em{$\bullet$\hfil}\ignorespaces}

\def\term#1{{\tt #1}}

\hbox to \hsize{\hfil\bf Predicting Loan Outcomes using Machine Learning --- CS109a Project Milestone 5\hfil}
\hbox to \hsize{\hfil David Modjeska and Andrew Greene\hfil}

\doublecolumns

\sec{Scope of this Milestone}
In this paper, we continue our discussion of ``Lending Club'' (LC) dataset. In particular,
we will discuss our plans for the remainder of the project, {\it i.e.} the Poster and Website deliverables.

\sec{Proposal for Future Work}
Our final presentations will devote a module to each step in the data science pipeline.

\sec{Initial Context}
Before we begin the formal steps of the data science pipeline, we will set out the problem posed by the Lending Club data. We will summarize key points raised in the literature review that we conducted for milestone 2.

\sec{Data Collection}
This module will discuss some issues with the raw data provided by LC, as well as the need to acquire additional data for context.

The data in the Lending Club dataset covers the period 2008--2015, which includes the global\break ``Great Recession'' of 2007{\sc Q}4--2009{\sc Q}2.\footnote{$^*$}{Federal Reserve of St.~Louis, {\tt https://fred.stlouisfed.org/series/JHDUSRGDPBR}} In order to account for the variation in economic conditions, we felt it necessary to collect additional data reflecting economic conditions, and join that with the LC data. We used the Federal Reserve ``FRED'' database, and in our presentation we will discuss this process.

We will also discuss the role that selection bias plays in the raw LC data. In particular, the provided dataset only includes loans that were {\it approved} by Lending Club members.

\sec{Data Exploration}
In this module, we will revisit the highlights of Milestone 3. We will idenitify which of the available columns are response variables (such as ``recoveries''), which ones are tainted predictors (such as ``interest rate''), and which are candidate predictors (such as ``annual income'').

We will spend some time here discussing ways of using NLP and NLP-like methods to extract useful predictors from the free-text ``description'' field. Examples include the number of words, the richness of the vocabulary, and the rate of spelling errors.

We will also consider in more depth the importance of ``issue date'', which cannot serve directly as a future predictor but whose impact is clearly felt in the data. We will assess several methodolgies for compensating for this effect.

\sec{Data Modeling}
In this module, we will build a repertoire of models using the data sources developed in previous modules. For each, we will discuss its strengths and weaknesses. We will include a variety of ensemble techniques to combine these models, as well.

Specific model types that we will assess include:

\* Logistic Regression (both balanced and not)
\* QDA
\* Random Forests
\* AdaBoost
\* Support Vector Classifiers
\* Model Stacking

\sec{Data Analysis}
In this module, we will compare the models developed in the previous module. Based on the strongest model(s), we will look at which predictors have the strongest influence on the results.

We will also explore how different participants in the Lending Club have different measures of ``success''. For example, Lending Club as an institution wishes to improve their grading algorithm and set interest rates commensurate with risk. An individual investor, on the other hand, wishes to minimize the likelihood of default; alternatively, they may wish to maximize their total return, taking into account that a default often follows a history of {\it partial} payments and is thus not a total write-off. Choosing an appropriate loss function changes the selection of the most successful model, which is the focus of this module.

\sec{Visualization and Presentation of Results}
Throughout the remaining deliverables, high-quality visualizations and clarity in presentation will be a constant requirement. These are not a separate module; although they are given as the final step in the Data Science pipeline, the entirety of both the poster and website deliverables will be the manifestations of this step.

\singlecolumn
\bye

