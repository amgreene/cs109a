{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "David Modjeska and Andrew Greene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook isolates the code we use to load the data and do some last-minute pre-processing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Deal with our necessary importds\n",
    "\n",
    "import datetime\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy.io import mmread\n",
    "from sklearn.decomposition import TruncatedSVD as tSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Specify processed data files to generate - full/partial, partial %, and train/test\n",
    "### Note: this cell is the same in both notebooks\n",
    "\n",
    "# load and clean full dataset?\n",
    "#load_full = False\n",
    "load_full = True  # AMG\n",
    "\n",
    "# if not loading and cleaning full dataset, what sample percentage?\n",
    "sample_percent = 10\n",
    "\n",
    "if load_full:\n",
    "    pct_str = \"\"\n",
    "else: # not load_full\n",
    "    pct_str = str(sample_percent) + \"_pct\"\n",
    "    \n",
    "# use training or testing data to generate minor files?\n",
    "minor_use_train = True\n",
    "if minor_use_train:\n",
    "    mode_str = \"train\"\n",
    "else: # not minor_use_train\n",
    "    mode_str = \"test\"\n",
    "    \n",
    "### set intermediate file names\n",
    "dir_str = \"./intermediate_files/\"\n",
    "\n",
    "processed_data_train_file = dir_str + \"processed_data_\" + \"train\" + pct_str + \".json\"\n",
    "processed_data_test_file = dir_str + \"processed_data_\" + \"test\" + pct_str + \".json\"\n",
    "\n",
    "nlp_data_file = dir_str + \"nlp_data_\" + mode_str + pct_str + \".json\"\n",
    "nlp_data_train_file = dir_str + \"nlp_data_\" + mode_str + pct_str + \".json\"\n",
    "term_freqs_file = dir_str + \"term_freqs_\" + mode_str + pct_str + \".mtx\"\n",
    "diff_terms_file = dir_str + \"diff_terms_\" + mode_str + pct_str + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load processed data\n",
    "data = pd.read_json(processed_data_train_file)\n",
    "data_nlp = pd.read_json(nlp_data_file)\n",
    "desc_matrix_coo = mmread(term_freqs_file)\n",
    "desc_matrix = sp.sparse.csr_matrix(desc_matrix_coo)\n",
    "count_cols_df = pd.read_json(diff_terms_file)\n",
    "\n",
    "count_cols_bool = count_cols_df.values > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173805\n"
     ]
    }
   ],
   "source": [
    "print len(data) # Confirm that the number looks reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to do a little filtering here. As discussed in our writeup, we will limit ourselves to 36-month loans issued in the years 2011, 2012, and 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79052\n"
     ]
    }
   ],
   "source": [
    "model_loan_term = 36\n",
    "data_filtered = data[data.loan_term == model_loan_term]\n",
    "data_filtered = data_filtered[pd.to_datetime(data_filtered.issue_date).dt.year.isin([2011,2012,2013])]\n",
    "print len(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    38957\n",
       "2012    30170\n",
       "2011     9925\n",
       "Name: issue_date, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure we have a reasonable distribution of issue dates\n",
    "pd.to_datetime(data_filtered.issue_date).dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick top-level sanity-check of the data, using Pandas `describe` method (and transposing it so it first on screen better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidmodjeska/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>6.903144e+04</td>\n",
       "      <td>5.626822e+04</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4.200000e+04</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>8.400000e+04</td>\n",
       "      <td>7.141778e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpi</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>2.129961e-02</td>\n",
       "      <td>4.217134e-04</td>\n",
       "      <td>2.069586e-02</td>\n",
       "      <td>2.092454e-02</td>\n",
       "      <td>2.132448e-02</td>\n",
       "      <td>2.166709e-02</td>\n",
       "      <td>2.224093e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2_yrs</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.832085e-01</td>\n",
       "      <td>4.819232e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_len</th>\n",
       "      <td>38614.0</td>\n",
       "      <td>2.499745e+02</td>\n",
       "      <td>2.132272e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.544000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>2.437067e-03</td>\n",
       "      <td>1.136559e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.575150e-03</td>\n",
       "      <td>2.392426e-03</td>\n",
       "      <td>3.267855e-03</td>\n",
       "      <td>5.445891e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gdp</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>9.997262e-01</td>\n",
       "      <td>3.283828e-05</td>\n",
       "      <td>9.995987e-01</td>\n",
       "      <td>9.997036e-01</td>\n",
       "      <td>9.997311e-01</td>\n",
       "      <td>9.997524e-01</td>\n",
       "      <td>9.997853e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>3.620877e+06</td>\n",
       "      <td>2.750039e+06</td>\n",
       "      <td>5.852400e+04</td>\n",
       "      <td>1.341303e+06</td>\n",
       "      <td>2.380480e+06</td>\n",
       "      <td>5.875565e+06</td>\n",
       "      <td>1.023482e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inquiry_6_mos</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>7.952866e-01</td>\n",
       "      <td>9.543483e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>3.986631e+02</td>\n",
       "      <td>2.455526e+02</td>\n",
       "      <td>3.016000e+01</td>\n",
       "      <td>2.190400e+02</td>\n",
       "      <td>3.433900e+02</td>\n",
       "      <td>5.150800e+02</td>\n",
       "      <td>1.408130e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest_rate</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.283620e+01</td>\n",
       "      <td>3.946880e+00</td>\n",
       "      <td>5.420000e+00</td>\n",
       "      <td>9.990000e+00</td>\n",
       "      <td>1.299000e+01</td>\n",
       "      <td>1.561000e+01</td>\n",
       "      <td>2.589000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipr</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.183191e-05</td>\n",
       "      <td>6.397747e-06</td>\n",
       "      <td>1.276000e-07</td>\n",
       "      <td>6.920525e-06</td>\n",
       "      <td>1.084875e-05</td>\n",
       "      <td>1.591122e-05</td>\n",
       "      <td>4.245340e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amount</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.184697e+04</td>\n",
       "      <td>7.184559e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>6.500000e+03</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>3.500000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_subgrade</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>8.948996e+00</td>\n",
       "      <td>5.425375e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_term</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months_since_last_record</th>\n",
       "      <td>6604.0</td>\n",
       "      <td>8.627771e+01</td>\n",
       "      <td>2.573780e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.210000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_accounts</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.055114e+01</td>\n",
       "      <td>4.556530e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>5.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.058802e+02</td>\n",
       "      <td>5.312564e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.190052e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>8.443503e-03</td>\n",
       "      <td>3.693020e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.826174e-03</td>\n",
       "      <td>8.728256e-03</td>\n",
       "      <td>1.134363e-02</td>\n",
       "      <td>1.854648e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rir</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>4.066357e-04</td>\n",
       "      <td>3.158694e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.938443e-04</td>\n",
       "      <td>3.412435e-04</td>\n",
       "      <td>5.418374e-04</td>\n",
       "      <td>7.473309e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_accounts</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>2.370409e+01</td>\n",
       "      <td>1.115893e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>9.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>79052.0</td>\n",
       "      <td>1.073260e-03</td>\n",
       "      <td>6.921652e-05</td>\n",
       "      <td>9.665647e-04</td>\n",
       "      <td>9.991520e-04</td>\n",
       "      <td>1.081487e-03</td>\n",
       "      <td>1.139510e-03</td>\n",
       "      <td>1.168791e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verif_status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count          mean           std           min  \\\n",
       "annual_income             79052.0  6.903144e+04  5.626822e+04  5.000000e+03   \n",
       "cpi                       79052.0  2.129961e-02  4.217134e-04  2.069586e-02   \n",
       "delinq_2_yrs              79052.0  1.832085e-01  4.819232e-01  0.000000e+00   \n",
       "desc_len                  38614.0  2.499745e+02  2.132272e+02  1.000000e+00   \n",
       "dti                       79052.0  2.437067e-03  1.136559e-03  0.000000e+00   \n",
       "gdp                       79052.0  9.997262e-01  3.283828e-05  9.995987e-01   \n",
       "id                        79052.0  3.620877e+06  2.750039e+06  5.852400e+04   \n",
       "inquiry_6_mos             79052.0  7.952866e-01  9.543483e-01  0.000000e+00   \n",
       "installment               79052.0  3.986631e+02  2.455526e+02  3.016000e+01   \n",
       "interest_rate             79052.0  1.283620e+01  3.946880e+00  5.420000e+00   \n",
       "ipr                       79052.0  1.183191e-05  6.397747e-06  1.276000e-07   \n",
       "loan_amount               79052.0  1.184697e+04  7.184559e+03  1.000000e+03   \n",
       "loan_subgrade             79052.0  8.948996e+00  5.425375e+00  1.000000e+00   \n",
       "loan_term                 79052.0  3.600000e+01  0.000000e+00  3.600000e+01   \n",
       "months_since_last_record   6604.0  8.627771e+01  2.573780e+01  1.000000e+00   \n",
       "open_accounts             79052.0  1.055114e+01  4.556530e+00  1.000000e+00   \n",
       "recoveries                79052.0  1.058802e+02  5.312564e+02  0.000000e+00   \n",
       "revol_util                79052.0  8.443503e-03  3.693020e-03  0.000000e+00   \n",
       "rir                       79052.0  4.066357e-04  3.158694e-04  0.000000e+00   \n",
       "total_accounts            79052.0  2.370409e+01  1.115893e+01  2.000000e+00   \n",
       "unemploy                  79052.0  1.073260e-03  6.921652e-05  9.665647e-04   \n",
       "verif_status                  0.0           NaN           NaN           NaN   \n",
       "\n",
       "                                   25%           50%           75%  \\\n",
       "annual_income             4.200000e+04  6.000000e+04  8.400000e+04   \n",
       "cpi                       2.092454e-02  2.132448e-02  2.166709e-02   \n",
       "delinq_2_yrs              0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "desc_len                           NaN           NaN           NaN   \n",
       "dti                       1.575150e-03  2.392426e-03  3.267855e-03   \n",
       "gdp                       9.997036e-01  9.997311e-01  9.997524e-01   \n",
       "id                        1.341303e+06  2.380480e+06  5.875565e+06   \n",
       "inquiry_6_mos             0.000000e+00  1.000000e+00  1.000000e+00   \n",
       "installment               2.190400e+02  3.433900e+02  5.150800e+02   \n",
       "interest_rate             9.990000e+00  1.299000e+01  1.561000e+01   \n",
       "ipr                       6.920525e-06  1.084875e-05  1.591122e-05   \n",
       "loan_amount               6.500000e+03  1.000000e+04  1.500000e+04   \n",
       "loan_subgrade             6.000000e+00  7.000000e+00  1.200000e+01   \n",
       "loan_term                 3.600000e+01  3.600000e+01  3.600000e+01   \n",
       "months_since_last_record           NaN           NaN           NaN   \n",
       "open_accounts             7.000000e+00  1.000000e+01  1.300000e+01   \n",
       "recoveries                0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "revol_util                5.826174e-03  8.728256e-03  1.134363e-02   \n",
       "rir                       1.938443e-04  3.412435e-04  5.418374e-04   \n",
       "total_accounts            1.500000e+01  2.200000e+01  3.000000e+01   \n",
       "unemploy                  9.991520e-04  1.081487e-03  1.139510e-03   \n",
       "verif_status                       NaN           NaN           NaN   \n",
       "\n",
       "                                   max  \n",
       "annual_income             7.141778e+06  \n",
       "cpi                       2.224093e-02  \n",
       "delinq_2_yrs              2.000000e+00  \n",
       "desc_len                  4.544000e+03  \n",
       "dti                       5.445891e-03  \n",
       "gdp                       9.997853e-01  \n",
       "id                        1.023482e+07  \n",
       "inquiry_6_mos             3.000000e+00  \n",
       "installment               1.408130e+03  \n",
       "interest_rate             2.589000e+01  \n",
       "ipr                       4.245340e-05  \n",
       "loan_amount               3.500000e+04  \n",
       "loan_subgrade             3.400000e+01  \n",
       "loan_term                 3.600000e+01  \n",
       "months_since_last_record  1.210000e+02  \n",
       "open_accounts             5.200000e+01  \n",
       "recoveries                3.190052e+04  \n",
       "revol_util                1.854648e-02  \n",
       "rir                       7.473309e-03  \n",
       "total_accounts            9.100000e+01  \n",
       "unemploy                  1.168791e-03  \n",
       "verif_status                       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a couple of adjustments to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# earliest_credit is not really a good indicator -- we want to know how long has elapsed since then\n",
    "# See http://stackoverflow.com/questions/17414130/pandas-datetime-calculate-number-of-weeks-between-dates-in-two-columns\n",
    "data_filtered['months_since_earliest_credit'] = (\n",
    "    (pd.to_datetime(data_filtered.issue_date) - pd.to_datetime(data_filtered.earliest_credit))/np.timedelta64(1,'M')\n",
    ").round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate the predictors (everything except \"loan status\") and the outcome\n",
    "data_filtered_x = data_filtered.drop('loan_status', axis = 1)\n",
    "data_filtered_y = data_filtered['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy unstandardized columns for later profit calculation\n",
    "profit_data = data_filtered_x[['installment', 'loan_amount', 'recoveries']]\n",
    "recoveries_avg = profit_data.recoveries.sum() / float(np.count_nonzero(profit_data.recoveries))\n",
    "data_filtered_x = data_filtered_x.drop('recoveries', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data. (See the comment below for a detailed explanation of what that means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Certain columns in the raw data should not be in our model\n",
    "columns_not_to_expand = [\n",
    "    'description',     # free-text, so don't one-hot encode (NLP is separate)\n",
    "    'verif_status',    # not sure why this is posing a problem....\n",
    "    'loan_subgrade',   # tainted predictor\n",
    "    'id',              # unique to each row\n",
    "    'interest_rate',   # tainted predictor\n",
    "    'index',           # unique to each row\n",
    "    'issue_date',      # not useful in future, using economic indicators instead\n",
    "    'earliest_credit', # has been converted to months_since_earliest_credit\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given an input matrix X and the equivalent matrix X from the training set,\n",
    "#\n",
    "# (1) impute missing values (as \"MISSING\" for categorical, since the fact that \n",
    "# the value is missing may itself be significant; and using the median value\n",
    "# for continuous predictors)\n",
    "#\n",
    "# (2) expand categorical predictors into a set of one-hot-encoded columns \n",
    "# (using 0 and 1, and limiting ourselves to the 50 most common values in the\n",
    "# training set)\n",
    "#\n",
    "# (3) standardize continuous predictors using the mean and stdev of the\n",
    "# training set\n",
    "\n",
    "def expand_x(x, x_orig):\n",
    "    x_expanded = pd.DataFrame()\n",
    "    for colname in x_orig.columns:\n",
    "        if colname in columns_not_to_expand:\n",
    "            continue\n",
    "        print colname, x_orig[colname].dtype\n",
    "        if x_orig[colname].dtype == 'object':\n",
    "            values = x[colname].fillna('MISSING')\n",
    "            value_columns = x_orig[colname].fillna('MISSING').value_counts().index\n",
    "            if len(value_columns) > 50:\n",
    "                value_columns = value_columns[:50]\n",
    "            for val in value_columns:\n",
    "                x_expanded[colname + '__' + val.replace(' ', '_')] = (values == val).astype(int)\n",
    "        else:\n",
    "            values = x[colname].fillna(x[colname].median())\n",
    "            sd = np.nanstd(x_orig[colname])\n",
    "            if sd < 1e-10:\n",
    "                sd = 1\n",
    "            x_expanded[colname] = (values - np.nanmean(x_orig[colname]))/sd\n",
    "    return x_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes computed\n",
      "address_state object\n",
      "annual_income float64\n",
      "cpi float64\n",
      "delinq_2_yrs int64\n",
      "desc_len float64\n",
      "dti float64\n",
      "employ_length object\n",
      "employ_title object\n",
      "gdp float64\n",
      "home_owner object\n",
      "initial_list_status object\n",
      "inquiry_6_mos int64\n",
      "installment float64\n",
      "ipr float64\n",
      "loan_amount int64\n",
      "loan_purpose object\n",
      "loan_term int64\n",
      "months_since_last_record float64\n",
      "open_accounts int64\n",
      "revol_util float64\n",
      "rir float64\n",
      "total_accounts int64\n",
      "unemploy float64\n",
      "months_since_earliest_credit float64\n",
      "Training set has 19719 rows\n",
      "address_state object\n",
      "annual_income float64\n",
      "cpi float64\n",
      "delinq_2_yrs int64\n",
      "desc_len float64\n",
      "dti float64\n",
      "employ_length object\n",
      "employ_title object\n",
      "gdp float64\n",
      "home_owner object\n",
      "initial_list_status object\n",
      "inquiry_6_mos int64\n",
      "installment float64\n",
      "ipr float64\n",
      "loan_amount int64\n",
      "loan_purpose object\n",
      "loan_term int64\n",
      "months_since_last_record float64\n",
      "open_accounts int64\n",
      "revol_util float64\n",
      "rir float64\n",
      "total_accounts int64\n",
      "unemploy float64\n",
      "months_since_earliest_credit float64\n",
      "Test set has 59333 rows\n"
     ]
    }
   ],
   "source": [
    "# Get a more manageable sample\n",
    "np.random.seed(1729)\n",
    "sample_flags = np.random.random(len(data_filtered)) <= 0.25\n",
    "print \"Indexes computed\" \n",
    "\n",
    "# train set\n",
    "x_train = data_filtered_x.iloc[sample_flags, :]\n",
    "x_expanded = expand_x(x_train, x_train)\n",
    "print \"Training set has %d rows\" % (len(x_expanded),)\n",
    "\n",
    "# test set\n",
    "x_test_expanded = expand_x(data_filtered_x.iloc[~sample_flags, :], x_train)\n",
    "print \"Test set has %d rows\" % (len(x_test_expanded),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split response column\n",
    "y = data_filtered_y.iloc[sample_flags]\n",
    "y_test = data_filtered_y.iloc[~sample_flags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split profit data\n",
    "profit_data_train = profit_data.iloc[sample_flags, :]\n",
    "profit_data_test = profit_data.iloc[~sample_flags, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### filter NLP data\n",
    "filter_flags = data_nlp.loan_term.values == model_loan_term\n",
    "data_nlp_filtered = data_nlp.iloc[filter_flags]\n",
    "\n",
    "x_nlp_filtered = data_nlp_filtered.drop('loan_status', 1)\n",
    "y_nlp_filtered = data_nlp_filtered.loan_status\n",
    "\n",
    "desc_matrix_filtered = desc_matrix[filter_flags]\n",
    "count_cols_bool_filtered = count_cols_bool[filter_flags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### split NLP data into training and testing sets\n",
    "np.random.seed(1729)\n",
    "train_flags = np.random.random(data_nlp_filtered.shape[0]) < 0.7\n",
    "\n",
    "x_nlp_train = x_nlp_filtered.iloc[train_flags, :]\n",
    "y_nlp_train = y_nlp_filtered.iloc[train_flags]\n",
    "\n",
    "x_nlp_test = x_nlp_filtered.iloc[~train_flags, :]\n",
    "y_nlp_test = y_nlp_filtered.iloc[~train_flags]\n",
    "\n",
    "desc_matrix_train = pd.DataFrame(desc_matrix_filtered[train_flags, :].toarray())\n",
    "desc_matrix_test = pd.DataFrame(desc_matrix_filtered[~train_flags, :].toarray())\n",
    "\n",
    "count_cols_bool_train = pd.DataFrame(count_cols_bool_filtered[train_flags, :])\n",
    "count_cols_bool_test = pd.DataFrame(count_cols_bool_filtered[~train_flags, :])\n",
    "\n",
    "years_nlp = pd.to_datetime(x_nlp_train.issue_date).dt.year\n",
    "years_nlp_test = pd.to_datetime(x_nlp_test.issue_date).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### match indexes\n",
    "\n",
    "desc_matrix_train.index = x_nlp_train.index\n",
    "desc_matrix_test.index = x_nlp_test.index\n",
    "\n",
    "count_cols_bool_train.index = x_nlp_train.index\n",
    "count_cols_bool_test.index = x_nlp_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    50334\n",
       "True      8999\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect test proportion of good/bad loans\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19719"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify size of train set\n",
    "np.count_nonzero(x_expanded.loan_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# be prepared to split stuff up by year of issue\n",
    "years = pd.to_datetime(data_filtered_x.issue_date.iloc[sample_flags]).dt.year\n",
    "years_test = pd.to_datetime(data_filtered_x.issue_date.iloc[~sample_flags]).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA to predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address_state object\n",
      "annual_income float64\n",
      "cpi float64\n",
      "delinq_2_yrs int64\n",
      "desc_len float64\n",
      "dti float64\n",
      "employ_length object\n",
      "employ_title object\n",
      "gdp float64\n",
      "home_owner object\n",
      "initial_list_status object\n",
      "inquiry_6_mos int64\n",
      "installment float64\n",
      "ipr float64\n",
      "loan_amount int64\n",
      "loan_purpose object\n",
      "loan_term int64\n",
      "months_since_last_record float64\n",
      "open_accounts int64\n",
      "revol_util float64\n",
      "rir float64\n",
      "total_accounts int64\n",
      "unemploy float64\n",
      "months_since_earliest_credit float64\n"
     ]
    }
   ],
   "source": [
    "tsvd = tSVD(n_components = 100, random_state=1729)\n",
    "tsvd.fit(x_expanded)\n",
    "data_filtered_expanded_x_pca = pd.DataFrame(tsvd.transform(expand_x(data_filtered_x, x_train)))\n",
    "data_filtered_expanded_x_pca.index = data_filtered_x.index\n",
    "pca_cum_var_expl = np.cumsum(np.round(tsvd.explained_variance_ratio_, 4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max variance explained 99.62\n",
      "PCA: first and last columns where % variance explained >= 99: [64 99]\n"
     ]
    }
   ],
   "source": [
    "print \"max variance explained\", pca_cum_var_expl.max()\n",
    "print \"PCA: first and last columns where % variance explained >= 99:\", \\\n",
    "            np.where(pca_cum_var_expl >= 99)[0][[0, -1]]\n",
    "\n",
    "x_expanded_pca = data_filtered_expanded_x_pca.iloc[sample_flags, :73]\n",
    "x_test_expanded_pca = data_filtered_expanded_x_pca.iloc[~sample_flags, :73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsvd = tSVD(n_components = 500, random_state=1729)\n",
    "desc_matrix_filtered_pca = pd.DataFrame(tsvd.fit_transform(desc_matrix_filtered))\n",
    "desc_matrix_filtered_pca.index = x_nlp_filtered.index\n",
    "pca_cum_var_expl = np.cumsum(np.round(tsvd.explained_variance_ratio_, 4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max variance explained 85.08\n",
      "PCA: first and last columns where % variance explained >= 84: [221 499]\n"
     ]
    }
   ],
   "source": [
    "print \"max variance explained\", pca_cum_var_expl.max()\n",
    "print \"PCA: first and last columns where % variance explained >= 84:\", \\\n",
    "            np.where(pca_cum_var_expl >= 84)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_matrix_pca = desc_matrix_filtered_pca.iloc[train_flags, :]\n",
    "desc_matrix_test_pca = desc_matrix_filtered_pca.iloc[~train_flags, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
